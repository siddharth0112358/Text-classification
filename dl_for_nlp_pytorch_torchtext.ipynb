{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "dl-for-nlp-pytorch-torchtext.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWavDeJF8ino"
      },
      "source": [
        "# Deep Learning For NLP with PyTorch and Torchtext\n",
        "\n",
        "This is the companion code for my article in medium. There will be no further explanation here, just pure code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti1BB4lL_ZYo"
      },
      "source": [
        "https://pytorch.org/text/stable/index.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_JjRwo89Uzx",
        "outputId": "5ceae8e0-579c-434c-b9f2-ba8149ea52fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade torchtext"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6_o-36D8inq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchtext.legacy.data import Field \n",
        "from torchtext.legacy.data import Dataset, Example\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from torchtext.vocab import FastText\n",
        "from torchtext.vocab import CharNGram\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1v_fQ28inr",
        "outputId": "6475daf4-7fc2-4a5f-9030-d52625f8cfae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding = FastText('simple')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/wiki.simple.vec: 293MB [00:11, 25.9MB/s]                           \n",
            "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 110819/111051 [00:13<00:00, 8446.07it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUl2QPs8inr"
      },
      "source": [
        "# embedding_charngram = CharNGram()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH7yhTE08ins",
        "outputId": "e2ec0b96-6eaf-42ee-c0a6-47017427c2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "df = pd.DataFrame([\n",
        "    ['my name is Jack', 'Y'],\n",
        "    ['Hi I am Jack', 'Y'],\n",
        "    ['Hello There!', 'Y'],\n",
        "    ['Hi I am cooking', 'N'],\n",
        "    ['Hello are you there?', 'N'],\n",
        "    ['There is a bird there', 'N'],\n",
        "], columns=['text', 'label'])\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my name is Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi I am Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello There!</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi I am cooking</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello are you there?</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>There is a bird there</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    text label\n",
              "0        my name is Jack     Y\n",
              "1           Hi I am Jack     Y\n",
              "2           Hello There!     Y\n",
              "3        Hi I am cooking     N\n",
              "4   Hello are you there?     N\n",
              "5  There is a bird there     N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_fjMqUc8ins"
      },
      "source": [
        "text_field = Field(\n",
        "    sequential=True,\n",
        "    tokenize='basic_english', \n",
        "    fix_length=5,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# sadly have to apply preprocess manually\n",
        "preprocessed_text = df['text'].apply(\n",
        "    lambda x: text_field.preprocess(x)\n",
        ")\n",
        "\n",
        "# load fastext simple embedding with 300d\n",
        "text_field.build_vocab(\n",
        "    preprocessed_text, \n",
        "    vectors='fasttext.simple.300d'\n",
        ")\n",
        "\n",
        "# get the vocab instance\n",
        "vocab = text_field.vocab"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmBd3d9c8int",
        "outputId": "4ae27124-b065-4344-ae07-55c0455622f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# known token, in my case print 12\n",
        "print(vocab['are'])\n",
        "# unknown token, will print 0\n",
        "print(vocab['crazy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfdaADeP8int",
        "outputId": "460c96f5-30a8-4609-ee5b-884c9e8a4203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, r in df.iterrows():\n",
        "    print(list(r.values))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['my name is Jack', 'Y']\n",
            "['Hi I am Jack', 'Y']\n",
            "['Hello There!', 'Y']\n",
            "['Hi I am cooking', 'N']\n",
            "['Hello are you there?', 'N']\n",
            "['There is a bird there', 'N']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8zfAG7F8inu"
      },
      "source": [
        "# we still have to manually handle conversion from categorical to int\n",
        "ltoi = {l: i for i, l in enumerate(df['label'].unique())}\n",
        "df['label'] = df['label'].apply(lambda y: ltoi[y])\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhOPqEPS8inu"
      },
      "source": [
        "train_dataset, test_dataset = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anp3QfB8inu"
      },
      "source": [
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), \n",
        "    batch_sizes=(2, 2),\n",
        "    sort=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msTZMYrP8inv"
      },
      "source": [
        "class ModelParam(object):\n",
        "    def __init__(self, param_dict: dict = dict()):\n",
        "        self.input_size = param_dict.get('input_size', 0)\n",
        "        self.vocab_size = param_dict.get('vocab_size')\n",
        "        self.embedding_dim = param_dict.get('embedding_dim', 300)\n",
        "        self.target_dim = param_dict.get('target_dim', 2)\n",
        "        \n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            model_param.vocab_size, \n",
        "            model_param.embedding_dim\n",
        "        )\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding(x).view(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5iTJoTy8inv"
      },
      "source": [
        "class MyModelWithPretrainedEmbedding(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam, embedding):\n",
        "        super().__init__()\n",
        "        self.embedding = embedding\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding[x].reshape(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HfmtaCa8inv",
        "outputId": "645fdde8-4207-44cc-8e4e-aee00d3cdb92"
      },
      "source": [
        "model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=5\n",
        "    )\n",
        ")\n",
        "model = MyModel(model_param)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_losses = list()\n",
        "    for batch in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(batch.text.T)\n",
        "        loss = loss_function(prediction, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_losses.append(loss.item())\n",
        "    print('train loss on epoch {} : {:.3f}'.format(epoch, np.mean(epoch_losses)))\n",
        "    \n",
        "    test_losses = list()\n",
        "    for batch in test_iter:\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(batch.text.T)\n",
        "            loss = loss_function(prediction, batch.label)\n",
        "            \n",
        "            test_losses.append(loss.item())\n",
        "    \n",
        "    print('test loss on epoch {}: {:.3f}'.format(epoch, np.mean(test_losses)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss on epoch 0 : 0.439\n",
            "test loss on epoch 0: 5.784\n",
            "train loss on epoch 1 : 0.002\n",
            "test loss on epoch 1: 8.804\n",
            "train loss on epoch 2 : 0.000\n",
            "test loss on epoch 2: 11.002\n",
            "train loss on epoch 3 : 0.000\n",
            "test loss on epoch 3: 12.678\n",
            "train loss on epoch 4 : 0.000\n",
            "test loss on epoch 4: 13.999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}