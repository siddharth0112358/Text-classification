{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multi-label-text-classification-5c505fdedca8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/bert-multilabel-text-classification-a7f560db34e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "        stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "\n",
    "meta = pd.read_csv(\"/Users/patsnap/Desktop/Neo4J_and_other_codes/MovieSummaries/movie.metadata.tsv\", sep = '\\t', header = None)\n",
    "meta.columns = [\"movie_id\",1,\"movie_name\",3,4,5,6,7,\"genre\"]\n",
    "genres = meta[[\"movie_id\",\"movie_name\",\"genre\"]]\n",
    "plots = pd.read_csv(\"/Users/patsnap/Desktop/Neo4J_and_other_codes/MovieSummaries/plot_summaries.txt\", sep = '\\t', header = None)\n",
    "plots.columns = [\"movie_id\", \"plot\"]\n",
    "genres['movie_id'] = genres['movie_id'].astype(str)\n",
    "plots['movie_id'] = plots['movie_id'].astype(str)\n",
    "movies = pd.merge(plots, genres, on = 'movie_id')\n",
    "genres_lists = []\n",
    "\n",
    "for i in movies['genre']:\n",
    "    genres_lists.append(list(json.loads(i).values()))\n",
    "movies['genre'] = genres_lists\n",
    "movies['plot'] = movies['plot'].apply(clean_text)\n",
    "movies['plot'] = movies['plot'].apply(stemming)\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit_transform(movies['genre'])\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(movies['genre'])\n",
    "\n",
    "for idx, genre in enumerate(multilabel_binarizer.classes_):\n",
    "    movies[genre] = y[:,idx]\n",
    "movies.to_csv('/Users/patsnap/Desktop/Neo4J_and_other_codes/MovieSummaries/movies.csv')\n",
    "movies_new = pd.read_csv('/Users/patsnap/Desktop/Neo4J_and_other_codes/MovieSummaries/movies.csv')\n",
    "movies = movies_new\n",
    "movies.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(movies, random_state=42, test_size=0.30, shuffle=True)\n",
    "train_text = train['plot'].values.astype('U')\n",
    "test_text = test['plot'].values.astype('U')\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2', max_features = 10000)\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['movie_id', 'movie_name', 'plot', 'genre', 'Unnamed: 0'], axis=1)\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['movie_id', 'movie_name', 'plot', 'genre', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Relevance\n",
    "br_classifier = BinaryRelevance(GaussianNB())\n",
    "br_classifier.fit(x_train, y_train)\n",
    "br_predictions = br_classifier.predict(x_test)\n",
    "print(\"Accuracy = \",accuracy_score(y_test,br_predictions.toarray()))\n",
    "print(\"F1 score = \",F1_score(y_test,br_predictions, average=\"micro\"))\n",
    "print(\"Hamming loss = \",hamming_loss(y_test,br_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Powerset\n",
    "lp_classifier = LabelPowerset(LogisticRegression())\n",
    "lp_classifier.fit(x_train, y_train)\n",
    "lp_predictions = lp_classifier.predict(x_test)\n",
    "print(\"Accuracy = \",accuracy_score(y_test,lp_predictions))\n",
    "print(\"F1 score = \",f1_score(y_test,lp_predictions, average=\"micro\"))\n",
    "print(\"Hamming loss = \",hamming_loss(y_test,lp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLkNN\n",
    "ml_classifier = MLkNN(k=10)\n",
    "# to prevent errors when handling sparse matrices.\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "ml_classifier.fit(x_train, y_train)\n",
    "# predict\n",
    "ml_predictions = ml_classifier.predict(x_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,ml_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the next classifier we need to remove from y-train, y-test categories which equal 0 for all train samples\n",
    "y_train = train.drop(labels = ['movie_id', 'movie_name', 'plot', 'genre', 'Unnamed: 0'], axis=1)\n",
    "selected_labels = y_train.columns[y_train.sum(axis = 0, skipna = True) > 0].tolist()\n",
    "y_test = test.drop(labels = ['movie_id', 'movie_name', 'plot', 'genre', 'Unnamed: 0'], axis=1)\n",
    "y_train = y_train.filter(selected_labels, axis=1)\n",
    "y_test = y_test.filter(selected_labels, axis=1)\n",
    "x_train = vectorizer.transform(train_text)\n",
    "x_test = vectorizer.transform(test_text)\n",
    "cc_classifier = ClassifierChain(LogisticRegression(solver='warn'))\n",
    "cc_classifier.fit(x_train, y_train)\n",
    "cc_predictions_proba = cc_classifier.predict_proba(x_test)\n",
    "#for plotting metrics as a function of threashold\n",
    "th = []\n",
    "f = []\n",
    "ham = []\n",
    "ac = []\n",
    "for t in range (5,60): # threshold value\n",
    "    y_pred_new = (cc_predictions_proba >= t/100).astype(int)\n",
    "    print(\"t =\" ,t/100)\n",
    "    print(\"Accuracy = \",accuracy_score(y_test,y_pred_new))\n",
    "    print(\"F1 = \",f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "    print(\"Hamming loss = \",hamming_loss(y_test,y_pred_new))\n",
    "    th.append(t)\n",
    "    ac.append(accuracy_score(y_test,y_pred_new))\n",
    "    f.append(f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "    ham.append(hamming_loss(y_test,y_pred_new))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(th, f)\n",
    "    plt.plot(th, ham)\n",
    "    plt.plot(th, ac)\n",
    "    plt.legend(['F1', 'Hamming loss', 'Accuracy'], loc='center left', fontsize = 14)\n",
    "    plt.ylabel(\"metrics\", fontsize = 14)\n",
    "    plt.xlabel(\"threshold\", fontsize = 14)\n",
    "    plt.title(\"Classfier Chain Model\", fontsize = 18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
