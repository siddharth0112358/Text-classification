{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting texthero\n",
      "  Using cached texthero-1.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting wordcloud>=1.5.0\n",
      "  Using cached wordcloud-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (366 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from texthero) (1.20.3)\n",
      "Collecting spacy<3.0.0\n",
      "  Using cached spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.7/site-packages (from texthero) (0.22.1)\n",
      "Requirement already satisfied: nltk>=3.3 in /opt/conda/lib/python3.7/site-packages (from texthero) (3.4.5)\n",
      "Collecting gensim<4.0,>=3.6.0\n",
      "  Using cached gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "Collecting pandas>=1.0.2\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting unidecode>=1.1.1\n",
      "  Using cached Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from texthero) (5.4.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from texthero) (3.1.3)\n",
      "Requirement already satisfied: tqdm>=4.3 in /opt/conda/lib/python3.7/site-packages (from texthero) (4.42.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim<4.0,>=3.6.0->texthero) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim<4.0,>=3.6.0->texthero) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.1.0->texthero) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.2->texthero) (2019.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.2.0->texthero) (8.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22->texthero) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0->texthero) (59.5.0)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0->texthero) (2.26.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Using cached thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Using cached srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from wordcloud>=1.5.0->texthero) (8.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (2.2.0)\n",
      "Installing collected packages: murmurhash, cymem, wasabi, srsly, preshed, plac, catalogue, blis, thinc, smart-open, wordcloud, unidecode, spacy, pandas, gensim, texthero\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "Successfully installed blis-0.7.5 catalogue-1.0.0 cymem-2.0.6 gensim-3.8.3 murmurhash-1.0.6 pandas-1.3.5 plac-1.1.3 preshed-3.0.6 smart-open-5.2.1 spacy-2.3.7 srsly-1.0.5 texthero-1.1.0 thinc-7.4.5 unidecode-1.3.2 wasabi-0.9.0 wordcloud-1.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting mapply\n",
      "  Using cached mapply-0.1.9-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from mapply) (5.6.7)\n",
      "Requirement already satisfied: pathos>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from mapply) (0.2.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from mapply) (4.42.1)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.3.4)\n",
      "Requirement already satisfied: six>=1.7.3 in /opt/conda/lib/python3.7/site-packages (from ppft>=1.6.6.4->pathos>=0.2.0->mapply) (1.14.0)\n",
      "Installing collected packages: mapply\n",
      "Successfully installed mapply-0.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.4.0)\n",
      "Collecting torch==1.10.1\n",
      "  Using cached torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.10.1 torchvision-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting fast-bert\n",
      "  Downloading fast_bert-1.9.15-py3-none-any.whl (99 kB)\n",
      "     |████████████████████████████████| 99 kB 1.5 MB/s             \n",
      "\u001b[?25hCollecting fastprogress\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting pytorch-lamb\n",
      "  Downloading pytorch_lamb-1.0.0-py3-none-any.whl (4.4 kB)\n",
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from fast-bert) (8.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fast-bert) (1.3.5)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 46.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from fast-bert) (0.0)\n",
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "     |████████████████████████████████| 769 kB 74.0 MB/s            \n",
      "\u001b[?25hCollecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting python-box\n",
      "  Downloading python_box-5.4.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from fast-bert) (2.3.7)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fast-bert) (3.1.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (4.42.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (2.26.0)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (1.20.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (20.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fast-bert) (2019.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pytorch-lamb->fast-bert) (0.11.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lamb->fast-bert) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval->fast-bert) (0.22.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (7.4.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (59.5.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (3.0.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.0.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /root/.local/lib/python3.7/site-packages (from tensorboardX->fast-bert) (3.17.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->fast-bert) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fast-bert) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2.8)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->fast-bert) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->fast-bert) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-lamb->fast-bert) (3.7.4.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2->fast-bert) (7.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->pytorch-lamb->fast-bert) (8.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->fast-bert) (2.2.0)\n",
      "Installing collected packages: regex, tokenizers, tensorboardX, sentencepiece, sacremoses, transformers, seqeval, pytorch-lamb, python-box, fastprogress, fast-bert\n",
      "Successfully installed fast-bert-1.9.15 fastprogress-1.0.0 python-box-5.4.1 pytorch-lamb-1.0.0 regex-2021.11.10 sacremoses-0.0.47 sentencepiece-0.1.96 seqeval-1.2.2 tensorboardX-2.4.1 tokenizers-0.8.1rc1 transformers-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install texthero\n",
    "!pip install mapply\n",
    "# !pip install flair\n",
    "# !pip install simpletransformers\n",
    "# !pip install tensorboardx\n",
    "!pip install torchvision \n",
    "!pip install pandas -U\n",
    "!pip install fast-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize('cats')\n",
    "stop_words = stopwords.words('english')\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import mapply\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import datetime\n",
    "# import texthero as hero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapply.init(\n",
    "    n_workers=-1,\n",
    "    chunk_size=1,\n",
    "    max_chunks_per_worker=8,\n",
    "    progressbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secrets\n",
    "session = boto3.session.Session()\n",
    "client = session.client(\n",
    "    service_name='secretsmanager',\n",
    "    region_name=\"eu-west-1\"\n",
    ")\n",
    "sagemaker_session = sagemaker.Session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {\n",
    "    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n",
    "    \"doesn’t\": \"does not\", \"don't\": \"do not\", \"don’t\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\", \"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y’all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"ain’t\": \"am not\", \"aren’t\": \"are not\",\n",
    "    \"can’t\": \"cannot\", \"can’t’ve\": \"cannot have\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\", \"couldn’t’ve\": \"could not have\",\n",
    "    \"didn’t\": \"did not\", \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hadn’t’ve\": \"had not have\",\n",
    "    \"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he had\", \"he’d’ve\": \"he would have\", \"he’ll\": \"he will\", \"he’ll’ve\": \"he will have\",\n",
    "    \"he’s\": \"he is\", \"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\",\n",
    "    \"i’ll\": \"i will\", \"i’ll’ve\": \"i will have\", \"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\", \"it’d’ve\": \"it would have\",\n",
    "    \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\", \"it’s\": \"it is\", \"let’s\": \"let us\", \"ma’am\": \"madam\", \"mayn’t\": \"may not\",\n",
    "    \"might’ve\": \"might have\", \"mightn’t\": \"might not\", \"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\",\n",
    "    \"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\", \"o’clock\": \"of the clock\",\n",
    "    \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\", \"shan’t\": \"shall not\", \"sha’n’t\": \"shall not\", \"shan’t’ve\": \"shall not have\",\n",
    "    \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\", \"she’ll’ve\": \"she will have\", \"she’s\": \"she is\",\n",
    "    \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\", \"so’ve\": \"so have\", \"so’s\": \"so is\",\n",
    "    \"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\", \"there’d’ve\": \"there would have\",\n",
    "    \"there’s\": \"there is\", \"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\", \"they’ll’ve\": \"they will have\",\n",
    "    \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\", \"we’d’ve\": \"we would have\",\n",
    "    \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\",\n",
    "    \"what’ll’ve\": \"what will have\", \"what’re\": \"what are\", \"what’s\": \"what is\", \"what’ve\": \"what have\", \"when’s\": \"when is\",\n",
    "    \"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\",\n",
    "    \"who’ll’ve\": \"who will have\", \"who’s\": \"who is\", \"who’ve\": \"who have\",\"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\",\n",
    "    \"won’t\": \"will not\", \"won’t’ve\": \"will not have\", \"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\",\n",
    "    \"y’all\": \"you all\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\", \"y’all’d’ve\": \"you all would have\", \"y’all’re\": \"you all are\",\n",
    "    \"y’all’ve\": \"you all have\", \"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\",\n",
    "    \"you’re\": \"you are\", \"you’re\": \"you are\", \"you’ve\": \"you have\"\n",
    "}\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function expand the contractions if there's any\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titles_data(my_str):\n",
    "    my_str = my_str.lower()\n",
    "    \n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    my_str = my_str.replace(\"&#039;\", \"\")\n",
    "    \n",
    "    # Removing all the special Characters\n",
    "    my_str = my_str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    \n",
    "    # Removing all the non ASCII characters\n",
    "    my_str = my_str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    my_str = my_str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    my_str = my_str.replace(r'\\s+',' ')\n",
    "    \n",
    "    # Replacing Two or more dots with one\n",
    "    my_str = my_str.replace(r'\\.{2,}', ' ')\n",
    "    \n",
    "    # Expand contradictions\n",
    "    my_str = expand_contractions(my_str)\n",
    "    \n",
    "    my_str = \"\".join([char for char in my_str if char not in string.punctuation])\n",
    "    words = word_tokenize(my_str)\n",
    "    filtered  = [word for word in words if word not in stop_words]\n",
    "    lemmatize = [lemmatizer.lemmatize(word) for word in filtered]\n",
    "    return ' '.join(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review_text(my_str):\n",
    "    my_str = my_str.lower()\n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    my_str = my_str.replace(\"&#039;\", \"\")    \n",
    "    # Removing all the special Characters\n",
    "    my_str = my_str.replace(r'[^\\w\\d\\s]',' ')    \n",
    "    # Removing all the non ASCII characters\n",
    "    my_str = my_str.replace(r'[^\\x00-\\x7F]+',' ')    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    my_str = my_str.replace(r'^\\s+|\\s+?$','')    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    my_str = my_str.replace(r'\\s+',' ')   \n",
    "    # Replacing Two or more dots with one\n",
    "    my_str = my_str.replace(r'\\.{2,}', ' ')\n",
    "    # Expand contradictions\n",
    "    my_str = expand_contractions(my_str)\n",
    "    my_str = \"\".join([char for char in my_str if char not in string.punctuation])\n",
    "    \n",
    "    words = word_tokenize(my_str)\n",
    "    filtered  = [word for word in words if word not in stop_words]\n",
    "    lemmatize = [lemmatizer.lemmatize(word) for word in filtered]\n",
    "    return ' '.join(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data and Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/root/projects/MMIT/MMIT_message_monitor/data/drugsComTest_raw.tsv\", sep = '\\t')\n",
    "train = pd.read_csv(\"/root/projects/MMIT/MMIT_message_monitor/data/drugsComTrain_raw.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53766, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['review', 'rating']]\n",
    "train = train[['review', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23433ee2b9a409399aab370ff7c5592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=16.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a87f40c5bc4403fa58f12018decdfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=16.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['review'] = train['review'].mapply(lambda x: x.strip('\"'))\n",
    "test['review'] = test['review'].mapply(lambda x: x.strip('\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    50989\n",
       "9.0     27531\n",
       "1.0     21619\n",
       "8.0     18890\n",
       "7.0      9456\n",
       "5.0      8013\n",
       "2.0      6931\n",
       "3.0      6513\n",
       "6.0      6343\n",
       "4.0      5012\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    17016\n",
       "9.0      9177\n",
       "1.0      7299\n",
       "8.0      6156\n",
       "7.0      3091\n",
       "5.0      2710\n",
       "2.0      2334\n",
       "3.0      2205\n",
       "6.0      2119\n",
       "4.0      1659\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['review_cleaned'] = train['review'].mapply(lambda x: preprocess_review_text(x))\n",
    "# test['review_cleaned'] = test['review'].mapply(lambda x: preprocess_review_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review_cleaned'] = hero.clean(train['review'])\n",
    "test['review_cleaned'] = hero.clean(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has no side effect, I take it in combinatio...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>side effect take combination bystolic mg fish oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My son is halfway through his fourth week of I...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to take another oral contraceptive, whi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is my first time using any form of birth ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>first time using form birth control glad went ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suboxone has completely turned my life around....</td>\n",
       "      <td>9.0</td>\n",
       "      <td>suboxone completely turned life around feel he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  It has no side effect, I take it in combinatio...     9.0   \n",
       "1  My son is halfway through his fourth week of I...     8.0   \n",
       "2  I used to take another oral contraceptive, whi...     5.0   \n",
       "3  This is my first time using any form of birth ...     8.0   \n",
       "4  Suboxone has completely turned my life around....     9.0   \n",
       "\n",
       "                                      review_cleaned  \n",
       "0  side effect take combination bystolic mg fish oil  \n",
       "1  son halfway fourth week intuniv became concern...  \n",
       "2  used take another oral contraceptive pill cycl...  \n",
       "3  first time using form birth control glad went ...  \n",
       "4  suboxone completely turned life around feel he...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_rating(x):\n",
    "    if x < 4:\n",
    "        return 0\n",
    "    elif x > 3 and x < 8:\n",
    "        return 1\n",
    "    elif x > 7:\n",
    "        return 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121671b27a72408ca63186cd18783b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=16.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518ad0169e89462fb00ec283aec033b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=16.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train['new_rating'] = train['rating'].mapply(lambda x: new_rating(x))\n",
    "test['new_rating'] = test['rating'].mapply(lambda x: new_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    97410\n",
      "0    35063\n",
      "1    28824\n",
      "Name: new_rating, dtype: int64\n",
      "2    32349\n",
      "0    11838\n",
      "1     9579\n",
      "Name: new_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['new_rating'].value_counts())\n",
    "print(test['new_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([10605, 42909, 113792, 123174, 128652, 143619], dtype='int64')\n",
      "Int64Index([16938, 21617], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(train[train['review_cleaned'] == ''].index)\n",
    "print(test[test['review_cleaned'] == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.review_cleaned != '']\n",
    "test = test[test.review_cleaned != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(train[train['review_cleaned'] == ''].index)\n",
    "print(test[test['review_cleaned'] == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has no side effect, I take it in combinatio...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>side effect take combination bystolic mg fish oil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My son is halfway through his fourth week of I...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to take another oral contraceptive, whi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is my first time using any form of birth ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>first time using form birth control glad went ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suboxone has completely turned my life around....</td>\n",
       "      <td>9.0</td>\n",
       "      <td>suboxone completely turned life around feel he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  It has no side effect, I take it in combinatio...     9.0   \n",
       "1  My son is halfway through his fourth week of I...     8.0   \n",
       "2  I used to take another oral contraceptive, whi...     5.0   \n",
       "3  This is my first time using any form of birth ...     8.0   \n",
       "4  Suboxone has completely turned my life around....     9.0   \n",
       "\n",
       "                                      review_cleaned  new_rating  \n",
       "0  side effect take combination bystolic mg fish oil           2  \n",
       "1  son halfway fourth week intuniv became concern...           2  \n",
       "2  used take another oral contraceptive pill cycl...           1  \n",
       "3  first time using form birth control glad went ...           2  \n",
       "4  suboxone completely turned life around feel he...           2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data_fst/train_preprocessed.csv')\n",
    "test.to_csv('data_fst/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(train, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance_json(row):\n",
    "    cur_row = dict()\n",
    "    if len(row['review_cleaned']) < 100000:\n",
    "        cur_row['source'] = row['review_cleaned']\n",
    "        cur_row['labels'] = row['new_rating']\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = 'clean_review_new_rating.train'\n",
    "output_valid = 'clean_review_new_rating.validation'\n",
    "output_test = 'clean_review_new_rating.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120968\n",
      "40323\n",
      "53764\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "for idx, row in train.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_train, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "\n",
    "all_rows = []\n",
    "for idx, row in dev.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_valid, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "all_rows = []\n",
    "for idx, row in test.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_test, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/clean_review_new_rating.test'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(\n",
    "    path=output_train,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_valid,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_test,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance_json(row):\n",
    "    cur_row = dict()\n",
    "    if len(row['review_cleaned']) < 100000:\n",
    "        cur_row['source'] = row['review_cleaned']\n",
    "        cur_row['labels'] = row['rating']\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = 'clean_review_rating.train'\n",
    "output_valid = 'clean_review_rating.validation'\n",
    "output_test = 'clean_review_rating.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120968\n",
      "40323\n",
      "53764\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "for idx, row in train.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_train, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "\n",
    "all_rows = []\n",
    "for idx, row in dev.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_valid, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "all_rows = []\n",
    "for idx, row in test.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_test, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/clean_review_rating.test'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(\n",
    "    path=output_train,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_valid,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_test,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance_json(row):\n",
    "    cur_row = dict()\n",
    "    if len(row['review']) < 100000:\n",
    "        cur_row['source'] = row['review']\n",
    "        cur_row['labels'] = row['new_rating']\n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = 'review_new_rating.train'\n",
    "output_valid = 'review_new_rating.validation'\n",
    "output_test = 'review_new_rating.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120968\n",
      "40323\n",
      "53764\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "for idx, row in train.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_train, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "\n",
    "all_rows = []\n",
    "for idx, row in dev.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_valid, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "all_rows = []\n",
    "for idx, row in test.iterrows():\n",
    "    all_rows.append(transform_instance_json(row))\n",
    "print(len(all_rows))\n",
    "with open(output_test, 'w') as f:\n",
    "    for x in all_rows:\n",
    "        json.dump(x, f) \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/review_new_rating.test'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.upload_data(\n",
    "    path=output_train,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_valid,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")\n",
    "sagemaker_session.upload_data(\n",
    "    path=output_test,\n",
    "    bucket='evaluate-general',\n",
    "    key_prefix='MMIT_message_monitor/sentiment_analysis/final_datasets'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Blazingtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::200459656367:role/service-role/AmazonSageMaker-ExecutionRole-20210115T135625\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "  \n",
    "# Secrets\n",
    "session = boto3.session.Session()\n",
    "client = session.client(\n",
    "    service_name='secretsmanager',\n",
    "    region_name=\"eu-west-1\"\n",
    ")\n",
    "sagemaker_session = sagemaker.Session(session)\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data = 's3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/clean_review_new_rating.train'\n",
    "s3_validation_data = 's3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/clean_review_new_rating.validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://evaluate-general/MMIT_message_monitor/sentiment_analysis/final_datasets/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 685385470294.dkr.ecr.eu-west-1.amazonaws.com/blazingtext:1 (eu-west-1)\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri('eu-west-1', \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Create a model object set to using \"Pipe\" mode.\n",
    "mc_model = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      train_instance_type='ml.m5.xlarge',\n",
    "                                      train_volume_size = 100,\n",
    "                                      input_mode = 'Pipe',\n",
    "                                      output_path=s3_output_location,\n",
    "                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=15,\n",
    "                            min_count=2,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source', 'labels'],\n",
    "                                        input_mode='Pipe',\n",
    "                                        record_wrapping='RecordIO') \n",
    "\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source', 'labels'],\n",
    "                                        input_mode='Pipe',\n",
    "                                        record_wrapping='RecordIO') \n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 10:33:54 Starting - Starting the training job...\n",
      "2022-01-18 10:34:16 Starting - Launching requested ML instancesProfilerReport-1642502033: InProgress\n",
      "...\n",
      "2022-01-18 10:34:51 Starting - Preparing the instances for training.........\n",
      "2022-01-18 10:36:17 Downloading - Downloading input data...\n",
      "2022-01-18 10:36:44 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[01/18/2022 10:36:45 WARNING 140536472942208] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[01/18/2022 10:36:45 WARNING 140536472942208] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[01/18/2022 10:36:45 INFO 140536472942208] nvidia-smi took: 0.025252580642700195 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/18/2022 10:36:45 INFO 140536472942208] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34mRead 5M words\u001b[0m\n",
      "\u001b[34mNumber of words:  30207\u001b[0m\n",
      "\u001b[34mBuilt the vocabulary using PIPE stream\u001b[0m\n",
      "\u001b[34mInitialized producer thread..\u001b[0m\n",
      "\u001b[34mLoading validation data from PIPE channel:/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0484  Progress: 3.16%  Million Words/sec: 0.79 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0458  Progress: 8.35%  Million Words/sec: 0.92 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0432  Progress: 13.53%  Million Words/sec: 0.91 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0406  Progress: 18.87%  Million Words/sec: 1.03 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0379  Progress: 24.24%  Million Words/sec: 1.00 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0353  Progress: 29.37%  Million Words/sec: 1.03 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.808045\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0327  Progress: 34.64%  Million Words/sec: 0.97 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0302  Progress: 39.66%  Million Words/sec: 1.04 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.822975\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0276  Progress: 44.90%  Million Words/sec: 1.01 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.827464\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0250  Progress: 50.10%  Million Words/sec: 0.99 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.83659\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0223  Progress: 55.46%  Million Words/sec: 0.98 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.842394\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0198  Progress: 60.47%  Million Words/sec: 0.96 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0173  Progress: 65.49%  Million Words/sec: 1.00 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.847924\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0147  Progress: 70.60%  Million Words/sec: 0.98 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 11\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.845965\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0122  Progress: 75.69%  Million Words/sec: 0.99 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 12\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.847701\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 2 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0095  Progress: 81.02%  Million Words/sec: 0.98 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0068  Progress: 86.33%  Million Words/sec: 1.01 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 13\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.850231\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0042  Progress: 91.69%  Million Words/sec: 0.99 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 14\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.849536\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0016  Progress: 96.71%  Million Words/sec: 0.98 #####\u001b[0m\n",
      "\u001b[34mProducer exiting. Created buffers: 1814520\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 15\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.850454\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 0.98 #####\u001b[0m\n",
      "\n",
      "2022-01-18 10:38:17 Uploading - Uploading generated training model\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 0.98\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 76.96\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9985\u001b[0m\n",
      "\u001b[34mNumber of train examples: 120967\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.8505\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 40323\u001b[0m\n",
      "\n",
      "2022-01-18 10:39:58 Completed - Training job completed\n",
      "Training seconds: 217\n",
      "Billable seconds: 217\n"
     ]
    }
   ],
   "source": [
    "mc_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OlZIZGpAab_w",
    "outputId": "9588e099-6c8f-4918-8208-4091b179972d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting mapply\n",
      "  Using cached mapply-0.1.9-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from mapply) (5.6.7)\n",
      "Requirement already satisfied: pathos>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from mapply) (0.2.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from mapply) (4.42.1)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from pathos>=0.2.0->mapply) (0.3.4)\n",
      "Requirement already satisfied: six>=1.7.3 in /opt/conda/lib/python3.7/site-packages (from ppft>=1.6.6.4->pathos>=0.2.0->mapply) (1.14.0)\n",
      "Installing collected packages: mapply\n",
      "Successfully installed mapply-0.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.63.4-py3-none-any.whl (248 kB)\n",
      "     |████████████████████████████████| 248 kB 24.5 MB/s            \n",
      "\u001b[?25hCollecting regex\n",
      "  Using cached regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "Requirement already satisfied: tensorboard in /root/.local/lib/python3.7/site-packages (from simpletransformers) (2.6.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.4.1)\n",
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (0.22.1)\n",
      "Collecting transformers>=4.6.0\n",
      "  Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (2.26.0)\n",
      "Collecting wandb>=0.10.32\n",
      "  Using cached wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting streamlit\n",
      "  Using cached streamlit-1.4.0-py2.py3-none-any.whl (9.3 MB)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from simpletransformers) (1.20.3)\n",
      "Collecting tqdm>=4.47.0\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-1.17.0-py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (20.1)\n",
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.6.0->simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /root/.local/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (3.17.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (1.14.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Using cached sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (5.6.7)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (2.8.1)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Using cached yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Using cached subprocess32-3.5.4-py3-none-any.whl\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.10.32->simpletransformers) (7.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Using cached configparser-5.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->simpletransformers) (2.0.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.70.12.2)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (2021.11.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (3.8.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (6.0.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets->simpletransformers) (0.3.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->simpletransformers) (2019.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->simpletransformers) (0.14.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from streamlit->simpletransformers) (3.7.4.3)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (19.3.0)\n",
      "Collecting pympler>=0.9\n",
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Collecting base58\n",
      "  Using cached base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting tzlocal\n",
      "  Using cached tzlocal-4.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (6.1)\n",
      "Requirement already satisfied: watchdog in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Collecting validators\n",
      "  Using cached validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Collecting astor\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting blinker\n",
      "  Using cached blinker-1.4-py3-none-any.whl\n",
      "Collecting altair>=3.2.0\n",
      "  Using cached altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "Requirement already satisfied: cachetools>=4.0 in /root/.local/lib/python3.7/site-packages (from streamlit->simpletransformers) (4.2.2)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Using cached pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.35.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->simpletransformers) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /root/.local/lib/python3.7/site-packages (from tensorboard->simpletransformers) (1.40.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.10.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.0.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.0)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (2.4.6)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /opt/conda/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.4)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /opt/conda/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (4.3.3)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /root/.local/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb>=0.10.32->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.7.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->simpletransformers) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (2.2.0)\n",
      "Collecting backports.zoneinfo\n",
      "  Using cached backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from validators->streamlit->simpletransformers) (4.4.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.4)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (7.12.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.15.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.1.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2021.5-py2.py3-none-any.whl (339 kB)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.0.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.14.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.6.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (6.4.6)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (18.1.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (21.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (21.2.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.1.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.4.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.14.6)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.19)\n",
      "Installing collected packages: packaging, tzdata, smmap, backports.zoneinfo, tqdm, regex, pytz-deprecation-shim, gitdb, yaspin, xxhash, validators, tzlocal, tokenizers, subprocess32, shortuuid, sentry-sdk, sacremoses, pympler, pydeck, promise, huggingface-hub, GitPython, docker-pycreds, configparser, blinker, base58, astor, altair, wandb, transformers, streamlit, seqeval, sentencepiece, datasets, simpletransformers\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "Successfully installed GitPython-3.1.26 altair-4.2.0 astor-0.8.1 backports.zoneinfo-0.2.1 base58-2.1.1 blinker-1.4 configparser-5.2.0 datasets-1.17.0 docker-pycreds-0.4.0 gitdb-4.0.9 huggingface-hub-0.4.0 packaging-21.3 promise-2.3 pydeck-0.7.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 regex-2022.1.18 sacremoses-0.0.47 sentencepiece-0.1.96 sentry-sdk-1.5.2 seqeval-1.2.2 shortuuid-1.0.8 simpletransformers-0.63.4 smmap-5.0.0 streamlit-1.4.0 subprocess32-3.5.4 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.15.0 tzdata-2021.5 tzlocal-4.1 validators-0.18.2 wandb-0.12.9 xxhash-2.0.2 yaspin-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (1.5.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.20.3)\n",
      "Collecting torch==1.10.1\n",
      "  Using cached torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.10.1 torchvision-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting tensorboardx\n",
      "  Using cached tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /root/.local/lib/python3.7/site-packages (from tensorboardx) (3.17.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorboardx) (1.20.3)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardx) (1.14.0)\n",
      "Installing collected packages: tensorboardx\n",
      "Successfully installed tensorboardx-2.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mapply\n",
    "!pip install simpletransformers\n",
    "!pip install transformers -U\n",
    "!pip install torchvision\n",
    "!pip install tensorboardx\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aTDNbG7vap8l"
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import wandb\n",
    "import logging\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0GL6__VLcU-u",
    "outputId": "15d30c60-f0a3-48b6-e323-c8a51766d9ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "14TwtWZKrixP"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_fst/train_preprocessed.csv\")\n",
    "test = pd.read_csv(\"data_fst/test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_cleaned</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It has no side effect, I take it in combinatio...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>side effect take combination bystolic mg fish oil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My son is halfway through his fourth week of I...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I used to take another oral contraceptive, whi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is my first time using any form of birth ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>first time using form birth control glad went ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Suboxone has completely turned my life around....</td>\n",
       "      <td>9.0</td>\n",
       "      <td>suboxone completely turned life around feel he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  rating  \\\n",
       "0           0  It has no side effect, I take it in combinatio...     9.0   \n",
       "1           1  My son is halfway through his fourth week of I...     8.0   \n",
       "2           2  I used to take another oral contraceptive, whi...     5.0   \n",
       "3           3  This is my first time using any form of birth ...     8.0   \n",
       "4           4  Suboxone has completely turned my life around....     9.0   \n",
       "\n",
       "                                      review_cleaned  new_rating  \n",
       "0  side effect take combination bystolic mg fish oil           2  \n",
       "1  son halfway fourth week intuniv became concern...           2  \n",
       "2  used take another oral contraceptive pill cycl...           1  \n",
       "3  first time using form birth control glad went ...           2  \n",
       "4  suboxone completely turned life around feel he...           2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pbFp9fY3aqB1"
   },
   "outputs": [],
   "source": [
    "# def new_rating(x):\n",
    "#     if x == 'negative':\n",
    "#         return 0\n",
    "#     elif x == 'neutral':\n",
    "#         return 1\n",
    "#     elif x == 'positive':\n",
    "#         return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hrhWNZlgaqEs"
   },
   "outputs": [],
   "source": [
    "# train['new_rating'] = train['new_rating'].apply(lambda x: new_rating(x))\n",
    "# test['new_rating'] = test['new_rating'].apply(lambda x: new_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X1uid06jaqHC"
   },
   "outputs": [],
   "source": [
    "train_df = train[['review_cleaned', 'new_rating']]\n",
    "train_df.columns = ['text', 'label']\n",
    "\n",
    "train_df, eval_df = train_test_split(train_df, test_size=0.25, random_state=0)\n",
    "\n",
    "test_df = test[['review_cleaned', 'new_rating']]\n",
    "test_df.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSUPF568sRrB",
    "outputId": "5fc9626b-6ffe-4766-e385-f13985989539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120968, 2) (40323, 2) (53764, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102131</th>\n",
       "      <td>really like pill several types birth control o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41784</th>\n",
       "      <td>started birth control took relieve horrible pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66602</th>\n",
       "      <td>took restavit tablets last night 10pm fell asl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115337</th>\n",
       "      <td>one week 75mg day 3months part always clear sk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60319</th>\n",
       "      <td>3rd time past months quot pills day week quot ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "102131  really like pill several types birth control o...      2\n",
       "41784   started birth control took relieve horrible pe...      1\n",
       "66602   took restavit tablets last night 10pm fell asl...      1\n",
       "115337  one week 75mg day 3months part always clear sk...      1\n",
       "60319   3rd time past months quot pills day week quot ...      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SbXRKI25smPT"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = train_df.label.unique()\n",
    "sample_size = 10000\n",
    "\n",
    "for i in classes:\n",
    "    g = train_df[train_df.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_train_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oKDN6Xw6tJQk"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = eval_df.label.unique()\n",
    "sample_size = 5000\n",
    "\n",
    "for i in classes:\n",
    "    g = eval_df[eval_df.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_eval_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "unjMyhrBx9yR"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = test_df.label.unique()\n",
    "sample_size = 5000\n",
    "\n",
    "for i in classes:\n",
    "    g = test_df[test_df.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_test_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFR0IJL8yM39",
    "outputId": "36fe5214-9e3a-422d-a01f-250edb313f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    10000\n",
      "1    10000\n",
      "0    10000\n",
      "Name: label, dtype: int64 2    5000\n",
      "1    5000\n",
      "0    5000\n",
      "Name: label, dtype: int64 2    5000\n",
      "1    5000\n",
      "0    5000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_train_df['label'].value_counts(), new_eval_df['label'].value_counts(), new_test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NjH6ytiGyeIp"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CHso6tdtJEv",
    "outputId": "d51f4d8b-557f-48f1-b685-e457f9d52794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511,
     "referenced_widgets": [
      "58b9414b2b1943938cf085a44ca0dca8",
      "ef9c5c8dbc1448a58eae611e4d38f3e7",
      "76cd5de82a604c53b1aec2d4ecdb8fa2",
      "3bb20e0699cc41fd8eb47b92ba737830",
      "5678f8f0abf74029a804fd9f3317d8d7",
      "612354cdfd7049eb9931557742214989",
      "932bb846ec6d4ce582c38cae8615d5e1",
      "ae456253d65043c2bfe5d535ce38eb59",
      "fc2131277d1f45458e3447b1098f985e",
      "c71fd7dc47f34cb886ecccfb3b7fadd2",
      "ceb4bfdad0b84a77ab5dbad8e07e1045",
      "ff255d93817c40658abd0e1adc7c24ac",
      "d9eb0b78c3b74ade848df73d6d629131",
      "bbddeefde1444e8483e33eb6be6a5c14",
      "31b046271644436c828ab51989f34e54",
      "d22f8013d3e448ad892d284aa647df51",
      "73e29149fbef4c11856d984894fc8a23",
      "2e59c33c225c435cb9d5635a4797911b",
      "6b72888241a947c8889010f9e752886e",
      "e3953e23da384657864d76e36bfd64ae",
      "8577adabbf48464594527cb5a7d3a468",
      "3c84480da6ce406da3cfe4c803155eeb",
      "2337a0d81af647c89aef7df84935fab0",
      "6726f3c3e5944d19941540cb7b4f864a",
      "1cc6fbb8222f42448f97940132b73fa1",
      "2bf223f32a134c12ad4a5da97a0f1301",
      "f1802301f1174e04beb69f67d0970c73",
      "b5c54e356bc34b829a93e415f016b55e",
      "49b3cf9b50094ac7a86136cd85bbc7c6",
      "cb4b55acba9a4e21b1d82073be51381b",
      "b5aa713a7947407bab3875e3db3911f6",
      "dacbaa19093c4147844003ac760bc233",
      "34ace50d2a6449c09c98a5187d4615d3",
      "4b657293af9a4502a38d178e048d5d59",
      "1c32daf9390f4b1c9ec1a4c53a4e13e8",
      "de7fd89ba62247dca637a43d27aaa789",
      "cb58a786470349089c04966db96668c9",
      "ea231bf15dd6482cabac46acaba1f8af",
      "98a87f500cff4f7c93294e0311b71846",
      "fcc16c252df74979a215d2cb295d758a",
      "51cb290fecb8403c94bada8ed5b3f9bc",
      "c4f7c71aa0244609b702e541d694e265",
      "cc911489111f4433a2b4e75e6ce5709b",
      "85909ffcb5fd40e3950798ffb5800421",
      "859967550c2f43c4ad177990d7ac53a0",
      "a16cb35198ec49c887ae197d27a67254",
      "85517fd92ef7446b88f1155871da9808",
      "7827c715236b4e18a9e9b56cdeda91f8",
      "93fe7a695a3d44de9f67bcae142e1938",
      "09dad3a325574cbd90638418d1c4ee71",
      "08f528ce1da74b22936fe1cc5f6eca19",
      "e36f7e1e25c34289964dc8eceba91896",
      "1185c36bca4045169b3385dd2a8489e7",
      "69d9414217dd48eb8c97a81b392b5d7b",
      "fa5b333ff33d41bab8b2b3e691d1c201",
      "6ebd22b974014230a2401a940f37def1",
      "ffe567801a9a47c991946513b880df43",
      "177b666552504d97a5a6576587f30dba",
      "6533a36f20d24a41bfd0e6dd2f25f82d",
      "59776fb03a4f4a298d6b9cf065692c31",
      "d8f4676c284c4640bb71d91433677935",
      "05bfd1ddf073436bae2f3b63b19d2fa9",
      "41a516f2bfcb46759bdbb4d3b3cc6750",
      "9147a01c44ff4f7e9892fc80f09314aa",
      "2416df1f31094ea5a8cf3e5c32e28e04",
      "28586e996f364e829c4d4a45dda90023",
      "235dbda681e44186a355f2153b9d5a21",
      "540ebc1f76ea47c2bf8a43d81f25b620",
      "8d5e41a4d24849f49ea933551501d7f6",
      "9319cc7dcf31401d843e2e80235cd486",
      "e040ab704c4746bd8da982fa3ddf73be",
      "b8983fdebd334fcdbd83b11188e17f12",
      "a31106352d3c4edfb5adf134c5ddd908",
      "86e90180c61b4195acc0c496c7ef23de",
      "b30d26547929458a932017b6af883402",
      "9bfa8acf03a44204a50d1d71705c87bf",
      "4dc83a64b9b14c7faa634f33b9563d99",
      "506f32e196694fc0a273935dde006b53",
      "5366d58b683c44ce81a39831841643d6",
      "48ca8ba0464e451c88c427a18d5a8ca5",
      "73483f94bd3445f38173bb91e0e7cc7d",
      "2e312120460b4896ab6a005efee406e1",
      "15ed4e3590c2400bb0f9c0eb54d9827f",
      "e7999f35805a4c67b1204fbe14c206c3",
      "5cd0bd9acb2b49e491f98dc5dc60d5e8",
      "855be1bc9df142e0b42754ba68b716c8",
      "2269e9ba4e704e349d048f8830f1db6e",
      "e82b2657cf1e4d75a5307aab4a8824ad",
      "ad3c6fb49dee4133a780fb9ba42e355d",
      "441739aa442f4e92b134653e776b7731",
      "cfc73d1dea904bb699ad972ddabe4161",
      "1e8d1e80d34d4159bb33defe002ba49f",
      "2e988957db2148cbbf8096843df41d17",
      "bf34c91a9f25478e802f27bc63ca0db6",
      "08f80f19fe70476bbf06dcbc0438a15f",
      "7403fc08399544e09861314af178083f",
      "7e143c7199234bf3b8bccdf71feb03c8",
      "bcd3eedd752241378a05cb07e1a1e0a6",
      "e0cbbe6d69c648f5878b9a2cf389454f",
      "34f23ccbdab0461691484791972596db",
      "1936813ff2a24c16a669491b008c8232",
      "96536230e63d4b9c9ac5c724a440d2f5",
      "7fb90bcdd6b649e1b6897369d6675cf3",
      "06ac5754c29b4c988404bab31f69e37b",
      "73568f27313f46e891c388a0979de832",
      "49b8c6d05fe74496b974d0215eff01a5",
      "6ba4d5470baf408aadc8db75f233ce76",
      "e2c5d92f623942c0854b417a025245af",
      "7f3147242a48422082ff8a069b51fe94",
      "d84760e450934f8ea4c9416386c3381a",
      "2e74d651449840ec86b71c1b8d5040d3",
      "2629defd49c34bebb386c00563cc1d58",
      "a3037d0f0d194653888041248c635ed8",
      "762026030e1443baa598e31eeb49b71a",
      "b2acf87298224e33a37a26298f57008b",
      "69335e1ef5874e578f6fc845457b73ca",
      "5ef3303b6bf54ee89f69655e63991065",
      "faac48f746ca4a87b62535758e3ee952",
      "9a6f111f49bd47dc8e5a3e1bbc4946a5",
      "a8d21bb5b07d471cbbfd7a39d15209f9",
      "89f0bba15d334138a667b486be64e987"
     ]
    },
    "id": "_2gl7XACaqJp",
    "outputId": "efe90f2c-721a-46da-ca91-ba9b84ba3cc4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0def28fbfc541368a6f5fb7c2d717a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aa46e6028f408598ac5fa2b2497104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5e6d6db12a433ab8b185f9942ac033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08aaf1cba5f4b03aeba4487512df361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py:586: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c3fdd175b247b096abfab41a1d4d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b68b329edd79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnew_train_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_eval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     accuracy=lambda truth, predictions: accuracy_score(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     ),\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m                 )\n\u001b[1;32m    592\u001b[0m             train_dataset = self.load_and_cache_examples(\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             )\n\u001b[1;32m    595\u001b[0m         \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m   1804\u001b[0m                 \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                 \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m                 \u001b[0mno_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m             )\n\u001b[1;32m   1808\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         self.examples, self.labels = build_classification_dataset(\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36mbuild_classification_dataset\u001b[0;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    247\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_data_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                     )\n\u001b[1;32m    251\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a TransformerModel with modified attributes\n",
    "model = ClassificationModel('xlnet', 'xlnet-base-cased', num_labels=3, use_cuda=cuda_available, args={\n",
    "                            'learning_rate': 1e-5, 'num_train_epochs': 10, 'reprocess_input_data': True, 'overwrite_output_dir': True})\n",
    "\n",
    "# Train the model\n",
    "model.train_model(\n",
    "    new_train_df,\n",
    "    eval_df=new_eval_df,\n",
    "    accuracy=lambda truth, predictions: accuracy_score(\n",
    "        truth, [round(p) for p in predictions]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgQ4Bt2kgSEV"
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    new_test_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.5687740141128755, 'eval_loss': 0.8718097717285156}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.6484375 ,  2.19726562,  1.56933594],\n",
       "       [-2.26171875, -1.12207031,  3.2890625 ],\n",
       "       [-3.16210938, -0.09936523,  3.79101562],\n",
       "       ...,\n",
       "       [ 2.76953125,  0.58349609, -3.42382812],\n",
       "       [ 1.82714844,  1.39746094, -3.0546875 ],\n",
       "       [ 3.5859375 , -1.52441406, -2.77539062]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result)\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: fast-bert in /opt/conda/lib/python3.7/site-packages (1.9.15)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from fast-bert) (0.0)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from fast-bert) (3.2.1)\n",
      "Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.7/site-packages (from fast-bert) (2.4.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from fast-bert) (8.2.0)\n",
      "Requirement already satisfied: transformers==3.0.2 in /opt/conda/lib/python3.7/site-packages (from fast-bert) (3.0.2)\n",
      "Requirement already satisfied: python-box in /opt/conda/lib/python3.7/site-packages (from fast-bert) (5.4.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /opt/conda/lib/python3.7/site-packages (from fast-bert) (0.8.1rc1)\n",
      "Requirement already satisfied: fastprogress in /opt/conda/lib/python3.7/site-packages (from fast-bert) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fast-bert) (3.1.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fast-bert) (1.3.5)\n",
      "Requirement already satisfied: pytorch-lamb in /opt/conda/lib/python3.7/site-packages (from fast-bert) (1.0.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.7/site-packages (from fast-bert) (1.2.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (2.26.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (0.1.96)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (1.20.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (0.0.47)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (2022.1.18)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2->fast-bert) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fast-bert) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fast-bert) (2019.3)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lamb->fast-bert) (1.10.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pytorch-lamb->fast-bert) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval->fast-bert) (0.22.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /root/.local/lib/python3.7/site-packages (from spacy->fast-bert) (3.7.4.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (2.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (59.5.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.9.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (8.0.13)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->fast-bert) (1.0.6)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /root/.local/lib/python3.7/site-packages (from tensorboardX->fast-bert) (3.17.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy->fast-bert) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fast-bert) (1.14.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy->fast-bert) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2->fast-bert) (2021.10.8)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->fast-bert) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->fast-bert) (0.14.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy->fast-bert) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy->fast-bert) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->pytorch-lamb->fast-bert) (8.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy->fast-bert) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (3.0.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.8.1rc1\n",
      "    Uninstalling tokenizers-0.8.1rc1:\n",
      "      Successfully uninstalled tokenizers-0.8.1rc1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 3.0.2\n",
      "    Uninstalling transformers-3.0.2:\n",
      "      Successfully uninstalled transformers-3.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fast-bert 1.9.15 requires tokenizers==0.8.1.rc1, but you have tokenizers 0.10.3 which is incompatible.\n",
      "fast-bert 1.9.15 requires transformers==3.0.2, but you have transformers 4.15.0 which is incompatible.\u001b[0m\n",
      "Successfully installed tokenizers-0.10.3 transformers-4.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: torch==1.10.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.7/site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: tensorboardx in /opt/conda/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /root/.local/lib/python3.7/site-packages (from tensorboardx) (3.17.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorboardx) (1.20.3)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardx) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fast-bert\n",
    "!pip install transformers -U\n",
    "!pip install torchvision\n",
    "!pip install tensorboardx\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_fst/train.csv\").drop(['Unnamed: 0'], axis = 1)\n",
    "test = pd.read_csv(\"data_fst/test.csv\").drop(['Unnamed: 0'], axis = 1)\n",
    "val = pd.read_csv(\"data_fst/test.csv\").drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SbXRKI25smPT"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = train.label.unique()\n",
    "sample_size = 10000\n",
    "\n",
    "for i in classes:\n",
    "    g = train[train.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_train_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oKDN6Xw6tJQk"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = val.label.unique()\n",
    "sample_size = 3000\n",
    "\n",
    "for i in classes:\n",
    "    g = val[val.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_eval_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "unjMyhrBx9yR"
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "classes = test.label.unique()\n",
    "sample_size = 3000\n",
    "\n",
    "for i in classes:\n",
    "    g = test[test.label == i].sample(sample_size)\n",
    "    frames.append(g)\n",
    "\n",
    "new_test_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv(\"data_fst/new_train.csv\", index = False)\n",
    "new_test_df.to_csv(\"data_fst/new_test.csv\", index = False)\n",
    "new_eval_df.to_csv(\"data_fst/new_val.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.metrics import accuracy\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "logger = logging.getLogger()\n",
    "device_cuda = torch.device(\"cuda\")\n",
    "metrics = [{'name': 'accuracy', 'function': accuracy}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from fast_bert.data_cls import BertDataBunch\n",
    "\n",
    "DATA_PATH = '/root/projects/MMIT/MMIT_message_monitor/notebook/data_fst'\n",
    "LABEL_PATH = '/root/projects/MMIT/MMIT_message_monitor/notebook/data_fst'\n",
    "\n",
    "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
    "                          tokenizer='roberta-base',\n",
    "                          train_file='new_train.csv',\n",
    "                          val_file='new_val.csv',\n",
    "                          label_file='labels.csv',\n",
    "                          text_col='text',\n",
    "                          label_col='label',\n",
    "                          batch_size_per_gpu=16,\n",
    "                          max_seq_length=512,\n",
    "                          multi_gpu=True,\n",
    "                          multi_label=False,\n",
    "                          model_type='roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = '/root/projects/MMIT/MMIT_message_monitor/notebook/data_fst'\n",
    "\n",
    "learner = BertLearner.from_pretrained_model(\n",
    "\t\t\t\t\t\tdatabunch,\n",
    "\t\t\t\t\t\tpretrained_path='roberta-base',\n",
    "\t\t\t\t\t\tmetrics=metrics,\n",
    "\t\t\t\t\t\tdevice=device_cuda,\n",
    "\t\t\t\t\t\tlogger=logger,\n",
    "\t\t\t\t\t\toutput_dir=OUTPUT_DIR,\n",
    "\t\t\t\t\t\tfinetuned_wgts_path=None,\n",
    "\t\t\t\t\t\twarmup_steps=500,\n",
    "\t\t\t\t\t\tmulti_gpu=True,\n",
    "\t\t\t\t\t\tis_fp16=True,\n",
    "\t\t\t\t\t\tmulti_label=False,\n",
    "\t\t\t\t\t\tlogging_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='368' class='' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      19.63% [368/1875 48:56<3:20:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:25<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:23<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='282' class='' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [282/282 06:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6fc870eefb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Evaluate the model after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mschedule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warmup_cosine\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \t\t\toptimizer_type=\"lamb\")\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fast_bert/learner_cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, validate, return_results, schedule_type, optimizer_type)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# Run training step and get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fast_bert/learner_cls.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(epochs=6,\n",
    "\t\t\tlr=6e-5,\n",
    "\t\t\tvalidate=True, \t# Evaluate the model after each epoch\n",
    "\t\t\tschedule_type=\"warmup_cosine\",\n",
    "\t\t\toptimizer_type=\"lamb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
