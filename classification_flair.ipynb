{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /Users/patsnap/anaconda2/lib/python3.7/site-packages (0.4.5)\n",
      "Requirement already satisfied: transformers>=2.3.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (2.10.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (3.8.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.2.10)\n",
      "Requirement already satisfied: torch>=1.1.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.4.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (0.2.4)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.5.10)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (0.22)\n",
      "Requirement already satisfied: mpld3==0.3 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (4.41.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (3.1.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (0.3.0)\n",
      "Requirement already satisfied: regex in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (2017.9.23)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: pytest>=5.3.2 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (5.4.2)\n",
      "Requirement already satisfied: langdetect in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (1.0.7)\n",
      "Requirement already satisfied: tabulate in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from flair) (0.8.3)\n",
      "Requirement already satisfied: requests in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (0.1.85)\n",
      "Requirement already satisfied: packaging in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (19.2)\n",
      "Requirement already satisfied: sacremoses in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (0.0.38)\n",
      "Requirement already satisfied: numpy in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (1.18.5)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (0.7.0)\n",
      "Requirement already satisfied: filelock in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/patsnap/.local/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (1.10.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/patsnap/.local/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: future in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: cloudpickle in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (0.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.4.2)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (7.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.1.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Users/patsnap/.local/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.8.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.13.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from requests->transformers>=2.3.0->flair) (2019.9.11)\n",
      "Requirement already satisfied: click in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from sacremoses->transformers>=2.3.0->flair) (7.0)\n",
      "Requirement already satisfied: google-cloud-storage in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (1.26.0)\n",
      "Requirement already satisfied: boto3 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (1.12.31)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/patsnap/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (46.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/patsnap/.local/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (1.3.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (1.12.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim>=3.4.0->flair) (1.15.49)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.2.6)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (3.4.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.31->boto3->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.15.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (1.51.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/patsnap/.local/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (3.11.3)\n",
      "Requirement already satisfied: pytz in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (2019.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/patsnap/anaconda2/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage->smart-open>=1.7.0->gensim>=3.4.0->flair) (0.4.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 21:42:48,322 loading file /Users/patsnap/.flair/models/imdb-v0.4.pt\n",
      "Sentence above is:  [POSITIVE (0.6636101007461548)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence('Flair is pretty neat!')\n",
    "classifier.predict(sentence)\n",
    "# print sentence with predicted labels\n",
    "print('Sentence above is: ', sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair’s classification dataset format is based on the Facebook’s FastText format. \n",
    "\n",
    "        __label__<class_1>\\t<text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       v1                                                 v2 Unnamed: 2  \\\n",
      "5176  ham  Company is very good.environment is terrific a...        NaN   \n",
      "1250  ham  Ummmmmaah Many many happy returns of d day my ...        NaN   \n",
      "748   ham  Is there a reason we've not spoken this year? ...        NaN   \n",
      "\n",
      "     Unnamed: 3 Unnamed: 4  \n",
      "5176        NaN        NaN  \n",
      "1250        NaN        NaN  \n",
      "748         NaN        NaN  \n",
      "     label                                               text\n",
      "5176   ham  Company is very good.environment is terrific a...\n",
      "1250   ham  Ummmmmaah Many many happy returns of d day my ...\n",
      "748    ham  Is there a reason we've not spoken this year? ...\n",
      "             label                                               text\n",
      "5176  __label__ham  Company is very good.environment is terrific a...\n",
      "1250  __label__ham  Ummmmmaah Many many happy returns of d day my ...\n",
      "748   __label__ham  Is there a reason we've not spoken this year? ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/Users/patsnap/Desktop/Neo4J_and_other_codes/text_classification/spam.csv\", encoding='latin-1').sample(frac=1).drop_duplicates()\n",
    "print(data.head(3))\n",
    "data = data[['v1', 'v2']].rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "print(data.head(3))\n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "print(data.head(3))\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 21:49:56,667 Reading data from .\n",
      "2020-06-08 21:49:56,670 Train: train.csv\n",
      "2020-06-08 21:49:56,672 Dev: dev.csv\n",
      "2020-06-08 21:49:56,673 Test: test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 21:50:00,077 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 4135/4135 [00:00<00:00, 230710.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 21:50:00,121 [b'ham', b'spam']\n",
      "2020-06-08 21:50:00,175 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,176 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-08 21:50:00,177 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,180 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
      "2020-06-08 21:50:00,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,184 Parameters:\n",
      "2020-06-08 21:50:00,187  - learning_rate: \"0.1\"\n",
      "2020-06-08 21:50:00,189  - mini_batch_size: \"32\"\n",
      "2020-06-08 21:50:00,200  - patience: \"3\"\n",
      "2020-06-08 21:50:00,202  - anneal_factor: \"0.5\"\n",
      "2020-06-08 21:50:00,208  - max_epochs: \"10\"\n",
      "2020-06-08 21:50:00,213  - shuffle: \"True\"\n",
      "2020-06-08 21:50:00,216  - train_with_dev: \"False\"\n",
      "2020-06-08 21:50:00,222  - batch_growth_annealing: \"False\"\n",
      "2020-06-08 21:50:00,223 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,230 Model training base path: \".\"\n",
      "2020-06-08 21:50:00,233 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,239 Device: cpu\n",
      "2020-06-08 21:50:00,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:00,252 Embeddings storage mode: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 21:50:00,281 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:50:47,472 epoch 1 - iter 13/130 - loss 0.37714449 - samples/sec: 8.82\n",
      "2020-06-08 21:51:20,023 epoch 1 - iter 26/130 - loss 0.29513310 - samples/sec: 12.79\n",
      "2020-06-08 21:51:51,910 epoch 1 - iter 39/130 - loss 0.26151532 - samples/sec: 13.06\n",
      "2020-06-08 21:52:30,293 epoch 1 - iter 52/130 - loss 0.23365807 - samples/sec: 10.85\n",
      "2020-06-08 21:53:17,562 epoch 1 - iter 65/130 - loss 0.21558568 - samples/sec: 8.81\n",
      "2020-06-08 21:53:54,579 epoch 1 - iter 78/130 - loss 0.19767844 - samples/sec: 11.25\n",
      "2020-06-08 21:54:36,469 epoch 1 - iter 91/130 - loss 0.18322272 - samples/sec: 9.94\n",
      "2020-06-08 21:55:12,339 epoch 1 - iter 104/130 - loss 0.17251134 - samples/sec: 11.61\n",
      "2020-06-08 21:55:48,757 epoch 1 - iter 117/130 - loss 0.16295676 - samples/sec: 11.43\n",
      "2020-06-08 21:56:34,481 epoch 1 - iter 130/130 - loss 0.15653595 - samples/sec: 9.10\n",
      "2020-06-08 21:56:34,515 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:56:34,516 EPOCH 1 done: loss 0.1565 - lr 0.1000\n",
      "2020-06-08 21:57:22,541 DEV : loss 0.04402133822441101 - score 0.9787\n",
      "2020-06-08 21:57:22,583 BAD EPOCHS (no improvement): 0\n",
      "2020-06-08 21:57:27,473 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:57:34,754 epoch 2 - iter 13/130 - loss 0.06254183 - samples/sec: 57.20\n",
      "2020-06-08 21:57:42,531 epoch 2 - iter 26/130 - loss 0.06938901 - samples/sec: 53.70\n",
      "2020-06-08 21:57:50,588 epoch 2 - iter 39/130 - loss 0.07580923 - samples/sec: 51.96\n",
      "2020-06-08 21:57:57,197 epoch 2 - iter 52/130 - loss 0.08046030 - samples/sec: 63.28\n",
      "2020-06-08 21:58:05,407 epoch 2 - iter 65/130 - loss 0.08594298 - samples/sec: 50.94\n",
      "2020-06-08 21:58:15,574 epoch 2 - iter 78/130 - loss 0.08234800 - samples/sec: 41.16\n",
      "2020-06-08 21:58:22,333 epoch 2 - iter 91/130 - loss 0.07945543 - samples/sec: 61.75\n",
      "2020-06-08 21:58:28,682 epoch 2 - iter 104/130 - loss 0.07868851 - samples/sec: 65.83\n",
      "2020-06-08 21:58:33,999 epoch 2 - iter 117/130 - loss 0.07633013 - samples/sec: 78.58\n",
      "2020-06-08 21:58:39,646 epoch 2 - iter 130/130 - loss 0.07622881 - samples/sec: 73.96\n",
      "2020-06-08 21:58:39,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:58:39,672 EPOCH 2 done: loss 0.0762 - lr 0.1000\n",
      "2020-06-08 21:58:41,264 DEV : loss 0.02176741324365139 - score 0.9942\n",
      "2020-06-08 21:58:41,292 BAD EPOCHS (no improvement): 0\n",
      "2020-06-08 21:58:44,509 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:58:48,906 epoch 3 - iter 13/130 - loss 0.08979315 - samples/sec: 94.69\n",
      "2020-06-08 21:58:54,528 epoch 3 - iter 26/130 - loss 0.08077566 - samples/sec: 74.28\n",
      "2020-06-08 21:58:58,359 epoch 3 - iter 39/130 - loss 0.07267117 - samples/sec: 109.23\n",
      "2020-06-08 21:59:02,866 epoch 3 - iter 52/130 - loss 0.06889824 - samples/sec: 92.75\n",
      "2020-06-08 21:59:09,279 epoch 3 - iter 65/130 - loss 0.06249004 - samples/sec: 65.10\n",
      "2020-06-08 21:59:13,757 epoch 3 - iter 78/130 - loss 0.07148040 - samples/sec: 93.34\n",
      "2020-06-08 21:59:18,566 epoch 3 - iter 91/130 - loss 0.07697655 - samples/sec: 86.90\n",
      "2020-06-08 21:59:23,625 epoch 3 - iter 104/130 - loss 0.07305002 - samples/sec: 82.59\n",
      "2020-06-08 21:59:29,406 epoch 3 - iter 117/130 - loss 0.07007443 - samples/sec: 72.26\n",
      "2020-06-08 21:59:33,981 epoch 3 - iter 130/130 - loss 0.06817962 - samples/sec: 91.36\n",
      "2020-06-08 21:59:34,007 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:59:34,008 EPOCH 3 done: loss 0.0682 - lr 0.1000\n",
      "2020-06-08 21:59:35,829 DEV : loss 0.019781185314059258 - score 0.9942\n",
      "2020-06-08 21:59:35,869 BAD EPOCHS (no improvement): 1\n",
      "2020-06-08 21:59:39,293 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 21:59:46,039 epoch 4 - iter 13/130 - loss 0.07888236 - samples/sec: 61.70\n",
      "2020-06-08 21:59:51,042 epoch 4 - iter 26/130 - loss 0.07055575 - samples/sec: 87.08\n",
      "2020-06-08 21:59:56,793 epoch 4 - iter 39/130 - loss 0.07268498 - samples/sec: 72.62\n",
      "2020-06-08 22:00:01,864 epoch 4 - iter 52/130 - loss 0.07389267 - samples/sec: 82.42\n",
      "2020-06-08 22:00:05,834 epoch 4 - iter 65/130 - loss 0.06669700 - samples/sec: 105.46\n",
      "2020-06-08 22:00:10,182 epoch 4 - iter 78/130 - loss 0.06178248 - samples/sec: 96.16\n",
      "2020-06-08 22:00:14,347 epoch 4 - iter 91/130 - loss 0.05672139 - samples/sec: 100.46\n",
      "2020-06-08 22:00:19,535 epoch 4 - iter 104/130 - loss 0.06051182 - samples/sec: 80.57\n",
      "2020-06-08 22:00:23,936 epoch 4 - iter 117/130 - loss 0.06627284 - samples/sec: 95.04\n",
      "2020-06-08 22:00:28,872 epoch 4 - iter 130/130 - loss 0.06285607 - samples/sec: 84.69\n",
      "2020-06-08 22:00:28,896 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:00:28,897 EPOCH 4 done: loss 0.0629 - lr 0.1000\n",
      "2020-06-08 22:00:30,417 DEV : loss 0.016004610806703568 - score 0.9961\n",
      "2020-06-08 22:00:30,447 BAD EPOCHS (no improvement): 0\n",
      "2020-06-08 22:00:33,284 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:00:37,272 epoch 5 - iter 13/130 - loss 0.04499490 - samples/sec: 104.37\n",
      "2020-06-08 22:00:41,598 epoch 5 - iter 26/130 - loss 0.04187261 - samples/sec: 96.65\n",
      "2020-06-08 22:00:46,513 epoch 5 - iter 39/130 - loss 0.03891610 - samples/sec: 85.05\n",
      "2020-06-08 22:00:51,057 epoch 5 - iter 52/130 - loss 0.04831819 - samples/sec: 92.00\n",
      "2020-06-08 22:00:55,452 epoch 5 - iter 65/130 - loss 0.05307811 - samples/sec: 95.12\n",
      "2020-06-08 22:00:59,490 epoch 5 - iter 78/130 - loss 0.05580554 - samples/sec: 103.56\n",
      "2020-06-08 22:01:04,561 epoch 5 - iter 91/130 - loss 0.05544977 - samples/sec: 82.43\n",
      "2020-06-08 22:01:09,851 epoch 5 - iter 104/130 - loss 0.05484710 - samples/sec: 79.01\n",
      "2020-06-08 22:01:14,890 epoch 5 - iter 117/130 - loss 0.06124289 - samples/sec: 82.93\n",
      "2020-06-08 22:01:19,708 epoch 5 - iter 130/130 - loss 0.05896616 - samples/sec: 86.76\n",
      "2020-06-08 22:01:19,732 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:01:19,733 EPOCH 5 done: loss 0.0590 - lr 0.1000\n",
      "2020-06-08 22:01:21,259 DEV : loss 0.01924177072942257 - score 0.9923\n",
      "2020-06-08 22:01:21,289 BAD EPOCHS (no improvement): 1\n",
      "2020-06-08 22:01:21,291 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:01:26,867 epoch 6 - iter 13/130 - loss 0.06116244 - samples/sec: 74.62\n",
      "2020-06-08 22:01:30,990 epoch 6 - iter 26/130 - loss 0.04331614 - samples/sec: 101.48\n",
      "2020-06-08 22:01:36,286 epoch 6 - iter 39/130 - loss 0.06663391 - samples/sec: 78.89\n",
      "2020-06-08 22:01:41,141 epoch 6 - iter 52/130 - loss 0.06110479 - samples/sec: 86.15\n",
      "2020-06-08 22:01:46,029 epoch 6 - iter 65/130 - loss 0.05896017 - samples/sec: 85.60\n",
      "2020-06-08 22:01:50,446 epoch 6 - iter 78/130 - loss 0.05523262 - samples/sec: 94.77\n",
      "2020-06-08 22:01:55,232 epoch 6 - iter 91/130 - loss 0.05141975 - samples/sec: 87.39\n",
      "2020-06-08 22:02:00,538 epoch 6 - iter 104/130 - loss 0.05059496 - samples/sec: 78.79\n",
      "2020-06-08 22:02:05,011 epoch 6 - iter 117/130 - loss 0.05038226 - samples/sec: 93.49\n",
      "2020-06-08 22:02:09,009 epoch 6 - iter 130/130 - loss 0.04831123 - samples/sec: 104.82\n",
      "2020-06-08 22:02:09,034 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:02:09,034 EPOCH 6 done: loss 0.0483 - lr 0.1000\n",
      "2020-06-08 22:02:10,555 DEV : loss 0.01371720526367426 - score 0.9942\n",
      "2020-06-08 22:02:10,586 BAD EPOCHS (no improvement): 2\n",
      "2020-06-08 22:02:10,587 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:02:15,166 epoch 7 - iter 13/130 - loss 0.04055791 - samples/sec: 90.89\n",
      "2020-06-08 22:02:20,463 epoch 7 - iter 26/130 - loss 0.03217627 - samples/sec: 78.91\n",
      "2020-06-08 22:02:24,593 epoch 7 - iter 39/130 - loss 0.04950448 - samples/sec: 101.24\n",
      "2020-06-08 22:02:29,551 epoch 7 - iter 52/130 - loss 0.05653881 - samples/sec: 84.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 22:02:34,920 epoch 7 - iter 65/130 - loss 0.05686576 - samples/sec: 77.82\n",
      "2020-06-08 22:02:40,117 epoch 7 - iter 78/130 - loss 0.05415901 - samples/sec: 80.45\n",
      "2020-06-08 22:02:45,077 epoch 7 - iter 91/130 - loss 0.05013913 - samples/sec: 84.25\n",
      "2020-06-08 22:02:49,131 epoch 7 - iter 104/130 - loss 0.04935752 - samples/sec: 103.22\n",
      "2020-06-08 22:02:53,426 epoch 7 - iter 117/130 - loss 0.04655833 - samples/sec: 97.39\n",
      "2020-06-08 22:02:58,240 epoch 7 - iter 130/130 - loss 0.04683353 - samples/sec: 86.83\n",
      "2020-06-08 22:02:58,268 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:02:58,269 EPOCH 7 done: loss 0.0468 - lr 0.1000\n",
      "2020-06-08 22:02:59,936 DEV : loss 0.014583970420062542 - score 0.9942\n",
      "2020-06-08 22:02:59,974 BAD EPOCHS (no improvement): 3\n",
      "2020-06-08 22:02:59,976 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:03:05,048 epoch 8 - iter 13/130 - loss 0.02675190 - samples/sec: 82.06\n",
      "2020-06-08 22:03:09,333 epoch 8 - iter 26/130 - loss 0.02729293 - samples/sec: 97.64\n",
      "2020-06-08 22:03:13,462 epoch 8 - iter 39/130 - loss 0.02452494 - samples/sec: 101.33\n",
      "2020-06-08 22:03:18,892 epoch 8 - iter 52/130 - loss 0.03931960 - samples/sec: 76.97\n",
      "2020-06-08 22:03:23,065 epoch 8 - iter 65/130 - loss 0.03685568 - samples/sec: 100.32\n",
      "2020-06-08 22:03:28,141 epoch 8 - iter 78/130 - loss 0.03530070 - samples/sec: 82.41\n",
      "2020-06-08 22:03:32,941 epoch 8 - iter 91/130 - loss 0.04223468 - samples/sec: 87.13\n",
      "2020-06-08 22:03:37,378 epoch 8 - iter 104/130 - loss 0.04107921 - samples/sec: 94.33\n",
      "2020-06-08 22:03:42,651 epoch 8 - iter 117/130 - loss 0.04512384 - samples/sec: 79.25\n",
      "2020-06-08 22:03:46,995 epoch 8 - iter 130/130 - loss 0.04339571 - samples/sec: 96.37\n",
      "2020-06-08 22:03:47,020 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:03:47,021 EPOCH 8 done: loss 0.0434 - lr 0.1000\n",
      "2020-06-08 22:03:48,639 DEV : loss 0.019388459622859955 - score 0.9942\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-06-08 22:03:48,681 BAD EPOCHS (no improvement): 4\n",
      "2020-06-08 22:03:48,683 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:03:53,613 epoch 9 - iter 13/130 - loss 0.01197250 - samples/sec: 84.43\n",
      "2020-06-08 22:03:57,992 epoch 9 - iter 26/130 - loss 0.02941625 - samples/sec: 95.53\n",
      "2020-06-08 22:04:02,807 epoch 9 - iter 39/130 - loss 0.03227123 - samples/sec: 86.81\n",
      "2020-06-08 22:04:08,079 epoch 9 - iter 52/130 - loss 0.03381273 - samples/sec: 79.24\n",
      "2020-06-08 22:04:12,526 epoch 9 - iter 65/130 - loss 0.03153651 - samples/sec: 94.08\n",
      "2020-06-08 22:04:18,153 epoch 9 - iter 78/130 - loss 0.03018838 - samples/sec: 74.24\n",
      "2020-06-08 22:04:22,884 epoch 9 - iter 91/130 - loss 0.03131569 - samples/sec: 88.36\n",
      "2020-06-08 22:04:26,965 epoch 9 - iter 104/130 - loss 0.03097871 - samples/sec: 102.56\n",
      "2020-06-08 22:04:31,392 epoch 9 - iter 117/130 - loss 0.03222024 - samples/sec: 94.44\n",
      "2020-06-08 22:04:35,719 epoch 9 - iter 130/130 - loss 0.03252170 - samples/sec: 96.73\n",
      "2020-06-08 22:04:35,746 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:04:35,747 EPOCH 9 done: loss 0.0325 - lr 0.0500\n",
      "2020-06-08 22:04:37,405 DEV : loss 0.04382731765508652 - score 0.9845\n",
      "2020-06-08 22:04:37,448 BAD EPOCHS (no improvement): 1\n",
      "2020-06-08 22:04:37,450 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:04:42,185 epoch 10 - iter 13/130 - loss 0.03299986 - samples/sec: 87.91\n",
      "2020-06-08 22:04:46,617 epoch 10 - iter 26/130 - loss 0.04064668 - samples/sec: 94.40\n",
      "2020-06-08 22:04:50,945 epoch 10 - iter 39/130 - loss 0.03739216 - samples/sec: 96.67\n",
      "2020-06-08 22:04:55,387 epoch 10 - iter 52/130 - loss 0.03146345 - samples/sec: 94.19\n",
      "2020-06-08 22:04:59,713 epoch 10 - iter 65/130 - loss 0.03032201 - samples/sec: 96.75\n",
      "2020-06-08 22:05:04,702 epoch 10 - iter 78/130 - loss 0.02880494 - samples/sec: 83.82\n",
      "2020-06-08 22:05:10,162 epoch 10 - iter 91/130 - loss 0.02824043 - samples/sec: 76.54\n",
      "2020-06-08 22:05:14,872 epoch 10 - iter 104/130 - loss 0.02776129 - samples/sec: 88.77\n",
      "2020-06-08 22:05:20,681 epoch 10 - iter 117/130 - loss 0.03036978 - samples/sec: 71.90\n",
      "2020-06-08 22:05:25,165 epoch 10 - iter 130/130 - loss 0.02976852 - samples/sec: 93.26\n",
      "2020-06-08 22:05:25,189 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:05:25,190 EPOCH 10 done: loss 0.0298 - lr 0.0500\n",
      "2020-06-08 22:05:26,692 DEV : loss 0.027551524341106415 - score 0.9923\n",
      "2020-06-08 22:05:26,727 BAD EPOCHS (no improvement): 2\n",
      "2020-06-08 22:05:29,800 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-08 22:05:29,801 Testing using best model ...\n",
      "2020-06-08 22:05:29,811 loading file best-model.pt\n",
      "2020-06-08 22:06:14,064 0.9807\t0.9807\t0.9807\n",
      "2020-06-08 22:06:14,065 \n",
      "MICRO_AVG: acc 0.962 - f1-score 0.9807\n",
      "MACRO_AVG: acc 0.9176 - f1-score 0.9560500000000001\n",
      "ham        tp: 447 - fp: 9 - fn: 1 - tn: 60 - precision: 0.9803 - recall: 0.9978 - accuracy: 0.9781 - f1-score: 0.9890\n",
      "spam       tp: 60 - fp: 1 - fn: 9 - tn: 447 - precision: 0.9836 - recall: 0.8696 - accuracy: 0.8571 - f1-score: 0.9231\n",
      "2020-06-08 22:06:14,066 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9807,\n",
       " 'dev_score_history': [0.9787,\n",
       "  0.9942,\n",
       "  0.9942,\n",
       "  0.9961,\n",
       "  0.9923,\n",
       "  0.9942,\n",
       "  0.9942,\n",
       "  0.9942,\n",
       "  0.9845,\n",
       "  0.9923],\n",
       " 'train_loss_history': [0.15653595264571218,\n",
       "  0.07622880785940932,\n",
       "  0.0681796175271022,\n",
       "  0.06285607342679914,\n",
       "  0.05896615899848537,\n",
       "  0.04831122554695377,\n",
       "  0.04683353302467507,\n",
       "  0.043395707786476126,\n",
       "  0.032521696647521685,\n",
       "  0.029768515147644885],\n",
       " 'dev_loss_history': [tensor(0.0440),\n",
       "  tensor(0.0218),\n",
       "  tensor(0.0198),\n",
       "  tensor(0.0160),\n",
       "  tensor(0.0192),\n",
       "  tensor(0.0137),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0194),\n",
       "  tensor(0.0438),\n",
       "  tensor(0.0276)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 08:35:48,208 loading file ./best-model.pt\n",
      "[ham (0.999051034450531)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('./best-model.pt')\n",
    "sentence = Sentence('Hi. Yes mum, I will...')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#add discrete parameters\n",
    "search_space.add(Parameter.PARAMNAME, hp.choice, options=[1, 2, ..])\n",
    "#add continuous parameters\n",
    "search_space.add(Parameter.PARAMNAME, hp.uniform, low=0.0, high=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters list\n",
    "https://github.com/flairNLP/flair/blob/master/flair/hyperparameter/parameter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 08:40:33,287 Reading data from .\n",
      "2020-06-09 08:40:33,288 Train: train.csv\n",
      "2020-06-09 08:40:33,289 Dev: dev.csv\n",
      "2020-06-09 08:40:33,289 Test: test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 08:40:37,259 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4135/4135 [00:00<00:00, 261839.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 08:40:37,291 [b'ham', b'spam']\n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]2020-06-09 08:40:37,326 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,327 Evaluation run: 1\n",
      "2020-06-09 08:40:37,327 Evaluating parameter combination:\n",
      "2020-06-09 08:40:37,328 \tdropout: 0.42660427747990465\n",
      "2020-06-09 08:40:37,330 \tembeddings: /Users/patsnap/.flair/embeddings/glove.gensim,/Users/patsnap/.flair/embeddings/news-forward-0.4.1.pt,/Users/patsnap/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2020-06-09 08:40:37,332 \thidden_size: 256\n",
      "2020-06-09 08:40:37,333 \tlearning_rate: 0.15\n",
      "2020-06-09 08:40:37,335 \tmini_batch_size: 16\n",
      "2020-06-09 08:40:37,340 \trnn_layers: 2\n",
      "2020-06-09 08:40:37,342 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,413 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,414 Training run: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 08:40:37,650 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,651 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "    (rnn): GRU(4196, 256, num_layers=2, batch_first=True)\n",
      "    (dropout): Dropout(p=0.42660427747990465, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-09 08:40:37,652 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,652 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
      "2020-06-09 08:40:37,655 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,656 Parameters:\n",
      "2020-06-09 08:40:37,660  - learning_rate: \"0.15\"\n",
      "2020-06-09 08:40:37,664  - mini_batch_size: \"16\"\n",
      "2020-06-09 08:40:37,669  - patience: \"3\"\n",
      "2020-06-09 08:40:37,678  - anneal_factor: \"0.5\"\n",
      "2020-06-09 08:40:37,681  - max_epochs: \"10\"\n",
      "2020-06-09 08:40:37,682  - shuffle: \"True\"\n",
      "2020-06-09 08:40:37,684  - train_with_dev: \"False\"\n",
      "2020-06-09 08:40:37,685  - batch_growth_annealing: \"False\"\n",
      "2020-06-09 08:40:37,686 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,688 Model training base path: \"resources/results\"\n",
      "2020-06-09 08:40:37,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,693 Device: cpu\n",
      "2020-06-09 08:40:37,694 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:40:37,696 Embeddings storage mode: cpu\n",
      "2020-06-09 08:40:37,699 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 08:43:11,467 epoch 1 - iter 25/259 - loss 0.33417467 - samples/sec: 2.60\n",
      "2020-06-09 08:46:17,626 epoch 1 - iter 50/259 - loss 0.22071872 - samples/sec: 2.15\n",
      "2020-06-09 08:49:55,970 epoch 1 - iter 75/259 - loss 0.19253065 - samples/sec: 1.83\n",
      "2020-06-09 08:52:19,090 epoch 1 - iter 100/259 - loss 0.16933932 - samples/sec: 2.80\n",
      "2020-06-09 08:54:58,133 epoch 1 - iter 125/259 - loss 0.15414608 - samples/sec: 2.52\n",
      "2020-06-09 08:58:06,760 epoch 1 - iter 150/259 - loss 0.14045811 - samples/sec: 2.12\n",
      "2020-06-09 09:03:48,735 epoch 1 - iter 175/259 - loss 0.13035514 - samples/sec: 1.17\n",
      "2020-06-09 09:07:35,493 epoch 1 - iter 200/259 - loss 0.11705018 - samples/sec: 1.76\n",
      "2020-06-09 09:12:00,584 epoch 1 - iter 225/259 - loss 0.11436402 - samples/sec: 1.51\n",
      "2020-06-09 09:15:01,358 epoch 1 - iter 250/259 - loss 0.11354001 - samples/sec: 2.21\n",
      "2020-06-09 09:16:04,538 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:16:04,539 EPOCH 1 done: loss 0.1129 - lr 0.1500\n",
      "2020-06-09 09:19:41,500 DEV : loss 0.0247963797301054 - score 0.9923\n",
      "2020-06-09 09:19:41,556 BAD EPOCHS (no improvement): 0\n",
      "2020-06-09 09:19:41,601 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:20:11,988 epoch 2 - iter 25/259 - loss 0.04347711 - samples/sec: 13.17\n",
      "2020-06-09 09:20:45,083 epoch 2 - iter 50/259 - loss 0.04783906 - samples/sec: 12.10\n",
      "2020-06-09 09:21:17,980 epoch 2 - iter 75/259 - loss 0.04858785 - samples/sec: 12.16\n",
      "2020-06-09 09:21:49,945 epoch 2 - iter 100/259 - loss 0.05550494 - samples/sec: 12.52\n",
      "2020-06-09 09:22:20,306 epoch 2 - iter 125/259 - loss 0.04903338 - samples/sec: 13.18\n",
      "2020-06-09 09:22:51,893 epoch 2 - iter 150/259 - loss 0.05280824 - samples/sec: 12.66\n",
      "2020-06-09 09:23:22,944 epoch 2 - iter 175/259 - loss 0.05807062 - samples/sec: 12.88\n",
      "2020-06-09 09:23:55,019 epoch 2 - iter 200/259 - loss 0.05556300 - samples/sec: 12.47\n",
      "2020-06-09 09:24:25,053 epoch 2 - iter 225/259 - loss 0.05950298 - samples/sec: 13.32\n",
      "2020-06-09 09:24:57,291 epoch 2 - iter 250/259 - loss 0.05791673 - samples/sec: 12.41\n",
      "2020-06-09 09:25:09,076 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:25:09,077 EPOCH 2 done: loss 0.0577 - lr 0.1500\n",
      "2020-06-09 09:25:20,355 DEV : loss 0.04520482197403908 - score 0.9845\n",
      "2020-06-09 09:25:20,399 BAD EPOCHS (no improvement): 1\n",
      "2020-06-09 09:25:20,474 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:25:49,114 epoch 3 - iter 25/259 - loss 0.04470153 - samples/sec: 13.99\n",
      "2020-06-09 09:26:14,166 epoch 3 - iter 50/259 - loss 0.03984881 - samples/sec: 15.97\n",
      "2020-06-09 09:26:38,538 epoch 3 - iter 75/259 - loss 0.04746268 - samples/sec: 16.41\n",
      "2020-06-09 09:27:04,875 epoch 3 - iter 100/259 - loss 0.04177121 - samples/sec: 15.19\n",
      "2020-06-09 09:27:28,808 epoch 3 - iter 125/259 - loss 0.04538275 - samples/sec: 16.72\n",
      "2020-06-09 09:27:55,459 epoch 3 - iter 150/259 - loss 0.04387576 - samples/sec: 15.01\n",
      "2020-06-09 09:28:21,148 epoch 3 - iter 175/259 - loss 0.04022123 - samples/sec: 15.57\n",
      "2020-06-09 09:28:46,673 epoch 3 - iter 200/259 - loss 0.04092363 - samples/sec: 15.67\n",
      "2020-06-09 09:29:11,117 epoch 3 - iter 225/259 - loss 0.04283249 - samples/sec: 16.37\n",
      "2020-06-09 09:29:38,329 epoch 3 - iter 250/259 - loss 0.04261633 - samples/sec: 14.70\n",
      "2020-06-09 09:29:47,876 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:29:47,877 EPOCH 3 done: loss 0.0414 - lr 0.1500\n",
      "2020-06-09 09:29:55,748 DEV : loss 0.02211366780102253 - score 0.9903\n",
      "2020-06-09 09:29:55,780 BAD EPOCHS (no improvement): 2\n",
      "2020-06-09 09:29:55,782 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:30:23,164 epoch 4 - iter 25/259 - loss 0.03447693 - samples/sec: 14.61\n",
      "2020-06-09 09:30:49,121 epoch 4 - iter 50/259 - loss 0.03955019 - samples/sec: 15.41\n",
      "2020-06-09 09:31:12,900 epoch 4 - iter 75/259 - loss 0.03126185 - samples/sec: 16.82\n",
      "2020-06-09 09:31:39,701 epoch 4 - iter 100/259 - loss 0.02869462 - samples/sec: 14.93\n",
      "2020-06-09 09:32:02,143 epoch 4 - iter 125/259 - loss 0.03041591 - samples/sec: 17.82\n",
      "2020-06-09 09:32:25,570 epoch 4 - iter 150/259 - loss 0.02921772 - samples/sec: 17.08\n",
      "2020-06-09 09:32:50,319 epoch 4 - iter 175/259 - loss 0.03215797 - samples/sec: 16.16\n",
      "2020-06-09 09:33:14,319 epoch 4 - iter 200/259 - loss 0.03280029 - samples/sec: 16.67\n",
      "2020-06-09 09:33:38,673 epoch 4 - iter 225/259 - loss 0.03281941 - samples/sec: 16.43\n",
      "2020-06-09 09:34:03,695 epoch 4 - iter 250/259 - loss 0.03176532 - samples/sec: 15.99\n",
      "2020-06-09 09:34:11,544 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:34:11,545 EPOCH 4 done: loss 0.0308 - lr 0.1500\n",
      "2020-06-09 09:34:18,937 DEV : loss 0.020729059353470802 - score 0.9923\n",
      "2020-06-09 09:34:18,970 BAD EPOCHS (no improvement): 3\n",
      "2020-06-09 09:34:18,972 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:34:45,575 epoch 5 - iter 25/259 - loss 0.00909827 - samples/sec: 15.04\n",
      "2020-06-09 09:35:10,961 epoch 5 - iter 50/259 - loss 0.01725742 - samples/sec: 15.76\n",
      "2020-06-09 09:35:35,084 epoch 5 - iter 75/259 - loss 0.02417466 - samples/sec: 16.58\n",
      "2020-06-09 09:36:00,329 epoch 5 - iter 100/259 - loss 0.02152088 - samples/sec: 15.85\n",
      "2020-06-09 09:36:25,712 epoch 5 - iter 125/259 - loss 0.02301311 - samples/sec: 15.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 09:36:49,318 epoch 5 - iter 150/259 - loss 0.02544574 - samples/sec: 16.95\n",
      "2020-06-09 09:37:12,624 epoch 5 - iter 175/259 - loss 0.02751743 - samples/sec: 17.16\n",
      "2020-06-09 09:37:36,886 epoch 5 - iter 200/259 - loss 0.02898525 - samples/sec: 16.49\n",
      "2020-06-09 09:37:59,150 epoch 5 - iter 225/259 - loss 0.02725408 - samples/sec: 17.97\n",
      "2020-06-09 09:38:23,295 epoch 5 - iter 250/259 - loss 0.03028203 - samples/sec: 16.57\n",
      "2020-06-09 09:38:31,066 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:38:31,067 EPOCH 5 done: loss 0.0313 - lr 0.1500\n",
      "2020-06-09 09:38:38,461 DEV : loss 0.026333022862672806 - score 0.9903\n",
      "Epoch     5: reducing learning rate of group 0 to 7.5000e-02.\n",
      "  0%|          | 0/100 [58:01<?, ?trial/s, best loss=?]2020-06-09 09:38:38,515 BAD EPOCHS (no improvement): 4\n",
      "2020-06-09 09:38:38,517 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:39:02,144 epoch 6 - iter 25/259 - loss 0.01691077 - samples/sec: 16.93\n",
      "2020-06-09 09:39:26,463 epoch 6 - iter 50/259 - loss 0.01686528 - samples/sec: 16.45\n",
      "2020-06-09 09:39:49,422 epoch 6 - iter 75/259 - loss 0.02261771 - samples/sec: 17.42\n",
      "2020-06-09 09:40:15,063 epoch 6 - iter 100/259 - loss 0.02236626 - samples/sec: 15.60\n",
      "2020-06-09 09:40:39,655 epoch 6 - iter 125/259 - loss 0.02166482 - samples/sec: 16.27\n",
      "2020-06-09 09:41:02,981 epoch 6 - iter 150/259 - loss 0.02228190 - samples/sec: 17.15\n",
      "2020-06-09 09:41:32,046 epoch 6 - iter 175/259 - loss 0.02337445 - samples/sec: 13.76\n",
      "2020-06-09 09:41:55,228 epoch 6 - iter 200/259 - loss 0.02171029 - samples/sec: 17.26\n",
      "2020-06-09 09:42:27,222 epoch 6 - iter 225/259 - loss 0.02138432 - samples/sec: 12.50\n",
      "2020-06-09 09:42:56,129 epoch 6 - iter 250/259 - loss 0.02193536 - samples/sec: 13.84\n",
      "2020-06-09 09:43:05,936 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:43:05,937 EPOCH 6 done: loss 0.0227 - lr 0.0750\n",
      "2020-06-09 09:43:15,364 DEV : loss 0.021008174866437912 - score 0.9923\n",
      "2020-06-09 09:43:15,401 BAD EPOCHS (no improvement): 1\n",
      "2020-06-09 09:43:15,404 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:43:42,305 epoch 7 - iter 25/259 - loss 0.01279074 - samples/sec: 14.87\n",
      "2020-06-09 09:44:12,761 epoch 7 - iter 50/259 - loss 0.01369719 - samples/sec: 13.13\n",
      "2020-06-09 09:44:36,321 epoch 7 - iter 75/259 - loss 0.01273931 - samples/sec: 16.98\n",
      "2020-06-09 09:45:03,161 epoch 7 - iter 100/259 - loss 0.01351994 - samples/sec: 14.90\n",
      "2020-06-09 09:45:29,743 epoch 7 - iter 125/259 - loss 0.01458321 - samples/sec: 15.05\n",
      "2020-06-09 09:45:52,631 epoch 7 - iter 150/259 - loss 0.01306230 - samples/sec: 17.48\n",
      "2020-06-09 09:46:19,219 epoch 7 - iter 175/259 - loss 0.01322023 - samples/sec: 15.05\n",
      "2020-06-09 09:46:43,412 epoch 7 - iter 200/259 - loss 0.01383632 - samples/sec: 16.54\n",
      "2020-06-09 09:47:10,292 epoch 7 - iter 225/259 - loss 0.01530551 - samples/sec: 14.88\n",
      "2020-06-09 09:47:38,105 epoch 7 - iter 250/259 - loss 0.01559077 - samples/sec: 14.38\n",
      "2020-06-09 09:47:47,092 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:47:47,093 EPOCH 7 done: loss 0.0151 - lr 0.0750\n",
      "2020-06-09 09:47:54,668 DEV : loss 0.02863413095474243 - score 0.9923\n",
      "2020-06-09 09:47:54,700 BAD EPOCHS (no improvement): 2\n",
      "2020-06-09 09:47:54,702 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:48:23,438 epoch 8 - iter 25/259 - loss 0.01605310 - samples/sec: 13.92\n",
      "2020-06-09 09:48:48,840 epoch 8 - iter 50/259 - loss 0.01341946 - samples/sec: 15.75\n",
      "2020-06-09 09:49:14,879 epoch 8 - iter 75/259 - loss 0.01008259 - samples/sec: 15.36\n",
      "2020-06-09 09:49:49,470 epoch 8 - iter 100/259 - loss 0.01148735 - samples/sec: 11.56\n",
      "2020-06-09 09:50:22,984 epoch 8 - iter 125/259 - loss 0.01030266 - samples/sec: 11.94\n",
      "2020-06-09 09:50:51,577 epoch 8 - iter 150/259 - loss 0.01039055 - samples/sec: 13.99\n",
      "2020-06-09 09:51:20,613 epoch 8 - iter 175/259 - loss 0.01275134 - samples/sec: 13.78\n",
      "2020-06-09 09:51:50,358 epoch 8 - iter 200/259 - loss 0.01359657 - samples/sec: 13.45\n",
      "2020-06-09 09:52:20,001 epoch 8 - iter 225/259 - loss 0.01306573 - samples/sec: 13.49\n",
      "2020-06-09 09:52:46,651 epoch 8 - iter 250/259 - loss 0.01285330 - samples/sec: 15.01\n",
      "2020-06-09 09:52:55,456 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:52:55,457 EPOCH 8 done: loss 0.0135 - lr 0.0750\n",
      "2020-06-09 09:53:03,799 DEV : loss 0.03137161210179329 - score 0.9865\n",
      "2020-06-09 09:53:03,841 BAD EPOCHS (no improvement): 3\n",
      "2020-06-09 09:53:03,844 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:53:30,070 epoch 9 - iter 25/259 - loss 0.00705878 - samples/sec: 15.25\n",
      "2020-06-09 09:53:58,589 epoch 9 - iter 50/259 - loss 0.00536537 - samples/sec: 14.03\n",
      "2020-06-09 09:54:26,809 epoch 9 - iter 75/259 - loss 0.00651393 - samples/sec: 14.18\n",
      "2020-06-09 09:54:55,110 epoch 9 - iter 100/259 - loss 0.00948261 - samples/sec: 14.14\n",
      "2020-06-09 09:55:21,628 epoch 9 - iter 125/259 - loss 0.00877554 - samples/sec: 15.09\n",
      "2020-06-09 09:55:53,115 epoch 9 - iter 150/259 - loss 0.01111264 - samples/sec: 12.70\n",
      "2020-06-09 09:56:22,050 epoch 9 - iter 175/259 - loss 0.01016134 - samples/sec: 13.83\n",
      "2020-06-09 09:56:54,894 epoch 9 - iter 200/259 - loss 0.00980883 - samples/sec: 12.18\n",
      "2020-06-09 09:57:21,992 epoch 9 - iter 225/259 - loss 0.01284603 - samples/sec: 14.76\n",
      "2020-06-09 09:57:47,955 epoch 9 - iter 250/259 - loss 0.01220521 - samples/sec: 15.41\n",
      "2020-06-09 09:57:58,617 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:57:58,618 EPOCH 9 done: loss 0.0120 - lr 0.0750\n",
      "2020-06-09 09:58:07,828 DEV : loss 0.028160104528069496 - score 0.9923\n",
      "Epoch     9: reducing learning rate of group 0 to 3.7500e-02.\n",
      "  0%|          | 0/100 [1:17:30<?, ?trial/s, best loss=?]2020-06-09 09:58:07,870 BAD EPOCHS (no improvement): 4\n",
      "2020-06-09 09:58:07,872 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 09:58:44,047 epoch 10 - iter 25/259 - loss 0.01072372 - samples/sec: 11.06\n",
      "2020-06-09 09:59:13,604 epoch 10 - iter 50/259 - loss 0.00780003 - samples/sec: 13.53\n",
      "2020-06-09 09:59:39,083 epoch 10 - iter 75/259 - loss 0.01229993 - samples/sec: 15.70\n",
      "2020-06-09 10:00:07,123 epoch 10 - iter 100/259 - loss 0.01405339 - samples/sec: 14.27\n",
      "2020-06-09 10:00:42,085 epoch 10 - iter 125/259 - loss 0.01294304 - samples/sec: 11.44\n",
      "2020-06-09 10:01:10,355 epoch 10 - iter 150/259 - loss 0.01313274 - samples/sec: 14.15\n",
      "2020-06-09 10:01:39,057 epoch 10 - iter 175/259 - loss 0.01236867 - samples/sec: 13.94\n",
      "2020-06-09 10:02:07,806 epoch 10 - iter 200/259 - loss 0.01201632 - samples/sec: 13.92\n",
      "2020-06-09 10:02:37,143 epoch 10 - iter 225/259 - loss 0.01113519 - samples/sec: 13.64\n",
      "2020-06-09 10:03:04,482 epoch 10 - iter 250/259 - loss 0.01024839 - samples/sec: 14.63\n",
      "2020-06-09 10:03:15,835 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:03:15,836 EPOCH 10 done: loss 0.0104 - lr 0.0375\n",
      "2020-06-09 10:03:25,891 DEV : loss 0.026706978678703308 - score 0.9923\n",
      "2020-06-09 10:03:25,948 BAD EPOCHS (no improvement): 1\n",
      "2020-06-09 10:03:25,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:03:25,960 Testing using best model ...\n",
      "2020-06-09 10:07:01,920 0.9826\t0.9826\t0.9826\n",
      "2020-06-09 10:07:01,922 \n",
      "MICRO_AVG: acc 0.9658 - f1-score 0.9826\n",
      "MACRO_AVG: acc 0.9276 - f1-score 0.96165\n",
      "ham        tp: 445 - fp: 6 - fn: 3 - tn: 63 - precision: 0.9867 - recall: 0.9933 - accuracy: 0.9802 - f1-score: 0.9900\n",
      "spam       tp: 63 - fp: 3 - fn: 6 - tn: 445 - precision: 0.9545 - recall: 0.9130 - accuracy: 0.8750 - f1-score: 0.9333\n",
      "2020-06-09 10:07:01,923 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:01,963 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 10:07:01,964 Done evaluating parameter combination:\n",
      "2020-06-09 10:07:01,966 \tdropout: 0.42660427747990465\n",
      "2020-06-09 10:07:01,968 \tembeddings: 0-/Users/patsnap/.flair/embeddings/glove.gensim,1-/Users/patsnap/.flair/embeddings/news-forward-0.4.1.pt,2-/Users/patsnap/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2020-06-09 10:07:01,969 \thidden_size: 256\n",
      "2020-06-09 10:07:01,970 \tlearning_rate: 0.15\n",
      "2020-06-09 10:07:01,971 \tmini_batch_size: 16\n",
      "2020-06-09 10:07:01,972 \trnn_layers: 2\n",
      "2020-06-09 10:07:01,973 score: 0.009633333333333346\n",
      "2020-06-09 10:07:01,974 variance: 7.475555555555338e-06\n",
      "2020-06-09 10:07:01,975 test_score: 0.9826\n",
      "\n",
      "2020-06-09 10:07:01,976 ----------------------------------------------------------------------------------------------------\n",
      "  1%|          | 1/100 [1:26:24<142:34:42, 5184.67s/trial, best loss: 0.009633333333333346]2020-06-09 10:07:02,044 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:02,045 Evaluation run: 2\n",
      "2020-06-09 10:07:02,046 Evaluating parameter combination:\n",
      "2020-06-09 10:07:02,047 \tdropout: 0.33151983481715513\n",
      "2020-06-09 10:07:02,054 \tembeddings: 0-/Users/patsnap/.flair/embeddings/glove.gensim,1-/Users/patsnap/.flair/embeddings/news-forward-0.4.1.pt,2-/Users/patsnap/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2020-06-09 10:07:02,058 \thidden_size: 256\n",
      "2020-06-09 10:07:02,060 \tlearning_rate: 0.2\n",
      "2020-06-09 10:07:02,063 \tmini_batch_size: 16\n",
      "2020-06-09 10:07:02,066 \trnn_layers: 1\n",
      "2020-06-09 10:07:02,068 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,452 Training run: 1\n",
      "2020-06-09 10:07:05,771 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,773 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "    (rnn): GRU(4196, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.33151983481715513, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-09 10:07:05,774 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,774 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
      "2020-06-09 10:07:05,776 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,777 Parameters:\n",
      "2020-06-09 10:07:05,778  - learning_rate: \"0.2\"\n",
      "2020-06-09 10:07:05,779  - mini_batch_size: \"16\"\n",
      "2020-06-09 10:07:05,780  - patience: \"3\"\n",
      "2020-06-09 10:07:05,782  - anneal_factor: \"0.5\"\n",
      "2020-06-09 10:07:05,783  - max_epochs: \"10\"\n",
      "2020-06-09 10:07:05,784  - shuffle: \"True\"\n",
      "2020-06-09 10:07:05,786  - train_with_dev: \"False\"\n",
      "2020-06-09 10:07:05,789  - batch_growth_annealing: \"False\"\n",
      "2020-06-09 10:07:05,791 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,792 Model training base path: \"resources/results\"\n",
      "2020-06-09 10:07:05,794 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,795 Device: cpu\n",
      "2020-06-09 10:07:05,796 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:07:05,798 Embeddings storage mode: cpu\n",
      "2020-06-09 10:07:05,802 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:10:00,625 epoch 1 - iter 25/259 - loss 0.22244160 - samples/sec: 2.29\n",
      "2020-06-09 10:12:39,929 epoch 1 - iter 50/259 - loss 0.22886115 - samples/sec: 2.51\n",
      "2020-06-09 10:15:59,458 epoch 1 - iter 75/259 - loss 0.17342927 - samples/sec: 2.00\n",
      "2020-06-09 10:19:06,009 epoch 1 - iter 100/259 - loss 0.14609976 - samples/sec: 2.14\n",
      "2020-06-09 10:21:59,763 epoch 1 - iter 125/259 - loss 0.12837093 - samples/sec: 2.30\n",
      "2020-06-09 10:25:10,003 epoch 1 - iter 150/259 - loss 0.12306487 - samples/sec: 2.10\n",
      "2020-06-09 10:27:46,864 epoch 1 - iter 175/259 - loss 0.11902861 - samples/sec: 2.55\n",
      "2020-06-09 10:30:41,295 epoch 1 - iter 200/259 - loss 0.11320690 - samples/sec: 2.29\n",
      "2020-06-09 10:33:37,332 epoch 1 - iter 225/259 - loss 0.10725599 - samples/sec: 2.27\n",
      "2020-06-09 10:36:42,827 epoch 1 - iter 250/259 - loss 0.10653481 - samples/sec: 2.16\n",
      "2020-06-09 10:37:41,988 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:37:41,990 EPOCH 1 done: loss 0.1065 - lr 0.2000\n",
      "2020-06-09 10:41:44,006 DEV : loss 0.02425321564078331 - score 0.9865\n",
      "2020-06-09 10:41:44,061 BAD EPOCHS (no improvement): 0\n",
      "2020-06-09 10:41:44,068 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:42:20,625 epoch 2 - iter 25/259 - loss 0.03556664 - samples/sec: 10.94\n",
      "2020-06-09 10:42:53,655 epoch 2 - iter 50/259 - loss 0.04263339 - samples/sec: 12.11\n",
      "2020-06-09 10:43:22,307 epoch 2 - iter 75/259 - loss 0.04107225 - samples/sec: 13.96\n",
      "2020-06-09 10:43:53,826 epoch 2 - iter 100/259 - loss 0.05448801 - samples/sec: 12.69\n",
      "2020-06-09 10:44:26,285 epoch 2 - iter 125/259 - loss 0.04736239 - samples/sec: 12.32\n",
      "2020-06-09 10:45:01,190 epoch 2 - iter 150/259 - loss 0.05057162 - samples/sec: 11.46\n",
      "2020-06-09 10:45:35,535 epoch 2 - iter 175/259 - loss 0.04974682 - samples/sec: 11.65\n",
      "2020-06-09 10:46:13,943 epoch 2 - iter 200/259 - loss 0.04748554 - samples/sec: 10.42\n",
      "2020-06-09 10:46:55,241 epoch 2 - iter 225/259 - loss 0.04741876 - samples/sec: 9.69\n",
      "2020-06-09 10:47:28,429 epoch 2 - iter 250/259 - loss 0.04652038 - samples/sec: 12.05\n",
      "2020-06-09 10:47:38,163 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:47:38,164 EPOCH 2 done: loss 0.0484 - lr 0.2000\n",
      "2020-06-09 10:47:48,056 DEV : loss 0.030731724575161934 - score 0.9884\n",
      "2020-06-09 10:47:48,105 BAD EPOCHS (no improvement): 0\n",
      "2020-06-09 10:47:48,167 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:48:19,188 epoch 3 - iter 25/259 - loss 0.02355755 - samples/sec: 12.90\n",
      "2020-06-09 10:49:02,131 epoch 3 - iter 50/259 - loss 0.02362659 - samples/sec: 9.32\n",
      "2020-06-09 10:49:30,335 epoch 3 - iter 75/259 - loss 0.02714184 - samples/sec: 14.19\n",
      "2020-06-09 10:49:59,302 epoch 3 - iter 100/259 - loss 0.02523813 - samples/sec: 13.81\n",
      "2020-06-09 10:50:24,180 epoch 3 - iter 125/259 - loss 0.02742475 - samples/sec: 16.08\n",
      "2020-06-09 10:50:53,325 epoch 3 - iter 150/259 - loss 0.03053751 - samples/sec: 13.73\n",
      "2020-06-09 10:51:17,325 epoch 3 - iter 175/259 - loss 0.03087715 - samples/sec: 16.67\n",
      "2020-06-09 10:51:41,307 epoch 3 - iter 200/259 - loss 0.03674985 - samples/sec: 16.68\n",
      "2020-06-09 10:52:07,354 epoch 3 - iter 225/259 - loss 0.03670452 - samples/sec: 15.36\n",
      "2020-06-09 10:52:33,178 epoch 3 - iter 250/259 - loss 0.03819162 - samples/sec: 15.49\n",
      "2020-06-09 10:52:42,449 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:52:42,450 EPOCH 3 done: loss 0.0384 - lr 0.2000\n",
      "2020-06-09 10:52:50,005 DEV : loss 0.024963626638054848 - score 0.9942\n",
      "2020-06-09 10:52:50,071 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 10:52:50,080 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:53:16,035 epoch 4 - iter 25/259 - loss 0.03537118 - samples/sec: 15.41\n",
      "2020-06-09 10:53:41,244 epoch 4 - iter 50/259 - loss 0.04567709 - samples/sec: 15.87\n",
      "2020-06-09 10:54:06,370 epoch 4 - iter 75/259 - loss 0.04161712 - samples/sec: 15.92\n",
      "2020-06-09 10:54:31,670 epoch 4 - iter 100/259 - loss 0.03571075 - samples/sec: 15.81\n",
      "2020-06-09 10:54:56,819 epoch 4 - iter 125/259 - loss 0.03149224 - samples/sec: 15.91\n",
      "2020-06-09 10:55:24,026 epoch 4 - iter 150/259 - loss 0.03560795 - samples/sec: 14.70\n",
      "2020-06-09 10:55:49,201 epoch 4 - iter 175/259 - loss 0.03686586 - samples/sec: 15.89\n",
      "2020-06-09 10:56:15,110 epoch 4 - iter 200/259 - loss 0.03503803 - samples/sec: 15.44\n",
      "2020-06-09 10:56:42,789 epoch 4 - iter 225/259 - loss 0.03186551 - samples/sec: 14.45\n",
      "2020-06-09 10:57:07,081 epoch 4 - iter 250/259 - loss 0.03104917 - samples/sec: 16.47\n",
      "2020-06-09 10:57:14,929 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:57:14,930 EPOCH 4 done: loss 0.0302 - lr 0.2000\n",
      "2020-06-09 10:57:22,126 DEV : loss 0.02210685797035694 - score 0.9942\n",
      "2020-06-09 10:57:22,162 BAD EPOCHS (no improvement): 1\n",
      "2020-06-09 10:57:22,164 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 10:57:46,193 epoch 5 - iter 25/259 - loss 0.02618831 - samples/sec: 16.65\n",
      "2020-06-09 10:58:11,347 epoch 5 - iter 50/259 - loss 0.03285401 - samples/sec: 15.90\n",
      "2020-06-09 10:58:35,342 epoch 5 - iter 75/259 - loss 0.03370917 - samples/sec: 16.67\n",
      "2020-06-09 10:59:00,317 epoch 5 - iter 100/259 - loss 0.02843922 - samples/sec: 16.02\n",
      "2020-06-09 10:59:23,209 epoch 5 - iter 125/259 - loss 0.02356252 - samples/sec: 17.47\n",
      "2020-06-09 10:59:48,205 epoch 5 - iter 150/259 - loss 0.02256278 - samples/sec: 16.00\n",
      "2020-06-09 11:00:10,516 epoch 5 - iter 175/259 - loss 0.02228665 - samples/sec: 17.93\n",
      "2020-06-09 11:00:33,518 epoch 5 - iter 200/259 - loss 0.02361994 - samples/sec: 17.39\n",
      "2020-06-09 11:00:58,395 epoch 5 - iter 225/259 - loss 0.02214555 - samples/sec: 16.08\n",
      "2020-06-09 11:01:21,811 epoch 5 - iter 250/259 - loss 0.02057713 - samples/sec: 17.08\n",
      "2020-06-09 11:01:29,601 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:01:29,602 EPOCH 5 done: loss 0.0199 - lr 0.2000\n",
      "2020-06-09 11:01:36,980 DEV : loss 0.026808077469468117 - score 0.9923\n",
      "2020-06-09 11:01:37,014 BAD EPOCHS (no improvement): 2\n",
      "2020-06-09 11:01:37,016 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:02:00,547 epoch 6 - iter 25/259 - loss 0.01057758 - samples/sec: 17.00\n",
      "2020-06-09 11:02:24,162 epoch 6 - iter 50/259 - loss 0.02357798 - samples/sec: 16.94\n",
      "2020-06-09 11:02:47,971 epoch 6 - iter 75/259 - loss 0.02479459 - samples/sec: 16.80\n",
      "2020-06-09 11:03:10,443 epoch 6 - iter 100/259 - loss 0.02563079 - samples/sec: 17.80\n",
      "2020-06-09 11:03:35,179 epoch 6 - iter 125/259 - loss 0.02315134 - samples/sec: 16.17\n",
      "2020-06-09 11:03:56,655 epoch 6 - iter 150/259 - loss 0.02056820 - samples/sec: 18.63\n",
      "2020-06-09 11:04:22,075 epoch 6 - iter 175/259 - loss 0.02387562 - samples/sec: 15.74\n",
      "2020-06-09 11:05:39,550 epoch 6 - iter 200/259 - loss 0.02250421 - samples/sec: 5.16\n",
      "2020-06-09 11:29:58,325 epoch 6 - iter 225/259 - loss 0.02255262 - samples/sec: 0.27\n",
      "2020-06-09 11:30:33,622 epoch 6 - iter 250/259 - loss 0.02510718 - samples/sec: 11.34\n",
      "2020-06-09 11:30:42,830 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:30:42,831 EPOCH 6 done: loss 0.0247 - lr 0.2000\n",
      "2020-06-09 11:30:52,400 DEV : loss 0.02389727532863617 - score 0.9923\n",
      "2020-06-09 11:30:52,433 BAD EPOCHS (no improvement): 3\n",
      "2020-06-09 11:30:52,436 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:31:15,243 epoch 7 - iter 25/259 - loss 0.00575292 - samples/sec: 17.54\n",
      "2020-06-09 11:31:39,748 epoch 7 - iter 50/259 - loss 0.01242952 - samples/sec: 16.33\n",
      "2020-06-09 11:32:05,401 epoch 7 - iter 75/259 - loss 0.01087393 - samples/sec: 15.60\n",
      "2020-06-09 11:32:29,606 epoch 7 - iter 100/259 - loss 0.00858630 - samples/sec: 16.53\n",
      "2020-06-09 11:32:53,641 epoch 7 - iter 125/259 - loss 0.01562387 - samples/sec: 16.64\n",
      "2020-06-09 11:33:18,347 epoch 7 - iter 150/259 - loss 0.01549061 - samples/sec: 16.19\n",
      "2020-06-09 11:33:41,532 epoch 7 - iter 175/259 - loss 0.01422597 - samples/sec: 17.25\n",
      "2020-06-09 11:34:07,959 epoch 7 - iter 200/259 - loss 0.01317493 - samples/sec: 15.14\n",
      "2020-06-09 11:34:30,288 epoch 7 - iter 225/259 - loss 0.01308791 - samples/sec: 17.92\n",
      "2020-06-09 11:34:55,159 epoch 7 - iter 250/259 - loss 0.01662640 - samples/sec: 16.08\n",
      "2020-06-09 11:35:03,631 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:35:03,632 EPOCH 7 done: loss 0.0164 - lr 0.2000\n",
      "2020-06-09 11:35:10,366 DEV : loss 0.022040944546461105 - score 0.9942\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-01.                              \n",
      "  1%|          | 1/100 [2:54:33<142:34:42, 5184.67s/trial, best loss: 0.009633333333333346]2020-06-09 11:35:10,404 BAD EPOCHS (no improvement): 4\n",
      "2020-06-09 11:35:10,406 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:35:34,574 epoch 8 - iter 25/259 - loss 0.00737119 - samples/sec: 16.55\n",
      "2020-06-09 11:35:57,145 epoch 8 - iter 50/259 - loss 0.01055696 - samples/sec: 17.72\n",
      "2020-06-09 11:36:17,896 epoch 8 - iter 75/259 - loss 0.00968754 - samples/sec: 19.28\n",
      "2020-06-09 11:36:41,472 epoch 8 - iter 100/259 - loss 0.01169757 - samples/sec: 16.97\n",
      "2020-06-09 11:37:05,368 epoch 8 - iter 125/259 - loss 0.01047468 - samples/sec: 16.74\n",
      "2020-06-09 11:37:29,228 epoch 8 - iter 150/259 - loss 0.00991312 - samples/sec: 16.77\n",
      "2020-06-09 11:37:55,706 epoch 8 - iter 175/259 - loss 0.00896977 - samples/sec: 15.11\n",
      "2020-06-09 11:38:18,544 epoch 8 - iter 200/259 - loss 0.00795041 - samples/sec: 17.52\n",
      "2020-06-09 11:38:42,227 epoch 8 - iter 225/259 - loss 0.00751668 - samples/sec: 16.89\n",
      "2020-06-09 11:39:06,400 epoch 8 - iter 250/259 - loss 0.00701948 - samples/sec: 16.55\n",
      "2020-06-09 11:39:16,341 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:39:16,342 EPOCH 8 done: loss 0.0068 - lr 0.1000\n",
      "2020-06-09 11:39:23,179 DEV : loss 0.024461299180984497 - score 0.9923\n",
      "2020-06-09 11:39:23,216 BAD EPOCHS (no improvement): 1\n",
      "2020-06-09 11:39:23,217 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:39:45,678 epoch 9 - iter 25/259 - loss 0.01178329 - samples/sec: 17.81\n",
      "2020-06-09 11:40:07,714 epoch 9 - iter 50/259 - loss 0.00921125 - samples/sec: 18.15\n",
      "2020-06-09 11:40:34,522 epoch 9 - iter 75/259 - loss 0.00647025 - samples/sec: 14.92\n",
      "2020-06-09 11:41:00,923 epoch 9 - iter 100/259 - loss 0.00562389 - samples/sec: 15.15\n",
      "2020-06-09 11:41:24,600 epoch 9 - iter 125/259 - loss 0.00465618 - samples/sec: 16.89\n",
      "2020-06-09 11:41:47,470 epoch 9 - iter 150/259 - loss 0.00483830 - samples/sec: 17.49\n",
      "2020-06-09 11:42:10,441 epoch 9 - iter 175/259 - loss 0.00569875 - samples/sec: 17.41\n",
      "2020-06-09 11:42:32,974 epoch 9 - iter 200/259 - loss 0.00547305 - samples/sec: 17.75\n",
      "2020-06-09 11:42:56,237 epoch 9 - iter 225/259 - loss 0.00507088 - samples/sec: 17.20\n",
      "2020-06-09 11:43:21,511 epoch 9 - iter 250/259 - loss 0.00467457 - samples/sec: 15.83\n",
      "2020-06-09 11:43:30,167 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:43:30,169 EPOCH 9 done: loss 0.0046 - lr 0.1000\n",
      "2020-06-09 11:43:37,801 DEV : loss 0.024177290499210358 - score 0.9923\n",
      "2020-06-09 11:43:37,830 BAD EPOCHS (no improvement): 2\n",
      "2020-06-09 11:43:37,832 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:44:01,192 epoch 10 - iter 25/259 - loss 0.00026770 - samples/sec: 17.13\n",
      "2020-06-09 11:44:22,747 epoch 10 - iter 50/259 - loss 0.00148496 - samples/sec: 18.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-09 11:44:48,657 epoch 10 - iter 75/259 - loss 0.00974862 - samples/sec: 15.44\n",
      "2020-06-09 11:45:10,560 epoch 10 - iter 100/259 - loss 0.00797147 - samples/sec: 18.26\n",
      "2020-06-09 11:45:32,854 epoch 10 - iter 125/259 - loss 0.00814239 - samples/sec: 17.94\n",
      "2020-06-09 11:45:57,216 epoch 10 - iter 150/259 - loss 0.00720294 - samples/sec: 16.42\n",
      "2020-06-09 11:46:20,872 epoch 10 - iter 175/259 - loss 0.00662584 - samples/sec: 16.91\n",
      "2020-06-09 11:46:45,383 epoch 10 - iter 200/259 - loss 0.00612845 - samples/sec: 16.32\n",
      "2020-06-09 11:47:11,883 epoch 10 - iter 225/259 - loss 0.00599642 - samples/sec: 15.10\n",
      "2020-06-09 11:47:39,193 epoch 10 - iter 250/259 - loss 0.00556203 - samples/sec: 14.65\n",
      "2020-06-09 11:47:47,919 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:47:47,919 EPOCH 10 done: loss 0.0054 - lr 0.1000\n",
      "2020-06-09 11:47:58,627 DEV : loss 0.02171877957880497 - score 0.9942\n",
      "2020-06-09 11:47:58,661 BAD EPOCHS (no improvement): 3\n",
      "2020-06-09 11:47:58,663 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:47:58,665 Testing using best model ...\n",
      "2020-06-09 11:51:31,268 0.9845\t0.9845\t0.9845\n",
      "2020-06-09 11:51:31,269 \n",
      "MICRO_AVG: acc 0.9695 - f1-score 0.9845\n",
      "MACRO_AVG: acc 0.9356 - f1-score 0.9661\n",
      "ham        tp: 445 - fp: 5 - fn: 3 - tn: 64 - precision: 0.9889 - recall: 0.9933 - accuracy: 0.9823 - f1-score: 0.9911\n",
      "spam       tp: 64 - fp: 3 - fn: 5 - tn: 445 - precision: 0.9552 - recall: 0.9275 - accuracy: 0.8889 - f1-score: 0.9411\n",
      "2020-06-09 11:51:31,270 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:31,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:31,279 Done evaluating parameter combination:\n",
      "2020-06-09 11:51:31,280 \tdropout: 0.33151983481715513\n",
      "2020-06-09 11:51:31,282 \tembeddings: 0-0-/Users/patsnap/.flair/embeddings/glove.gensim,1-1-/Users/patsnap/.flair/embeddings/news-forward-0.4.1.pt,2-2-/Users/patsnap/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2020-06-09 11:51:31,283 \thidden_size: 256\n",
      "2020-06-09 11:51:31,285 \tlearning_rate: 0.2\n",
      "2020-06-09 11:51:31,287 \tmini_batch_size: 16\n",
      "2020-06-09 11:51:31,288 \trnn_layers: 1\n",
      "2020-06-09 11:51:31,290 score: 0.007066666666666703\n",
      "2020-06-09 11:51:31,292 variance: 8.02222222222233e-07\n",
      "2020-06-09 11:51:31,295 test_score: 0.9845\n",
      "\n",
      "2020-06-09 11:51:31,297 ----------------------------------------------------------------------------------------------------\n",
      "  2%|▏         | 2/100 [3:10:53<149:59:46, 5510.07s/trial, best loss: 0.007066666666666703]2020-06-09 11:51:31,324 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:31,326 Evaluation run: 3\n",
      "2020-06-09 11:51:31,328 Evaluating parameter combination:\n",
      "2020-06-09 11:51:31,332 \tdropout: 0.0955739851165136\n",
      "2020-06-09 11:51:31,334 \tembeddings: 0-0-/Users/patsnap/.flair/embeddings/glove.gensim,1-1-/Users/patsnap/.flair/embeddings/news-forward-0.4.1.pt,2-2-/Users/patsnap/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2020-06-09 11:51:31,339 \thidden_size: 256\n",
      "2020-06-09 11:51:31,341 \tlearning_rate: 0.1\n",
      "2020-06-09 11:51:31,345 \tmini_batch_size: 64\n",
      "2020-06-09 11:51:31,346 \trnn_layers: 1\n",
      "2020-06-09 11:51:31,349 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,115 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,116 Training run: 1\n",
      "2020-06-09 11:51:34,421 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,422 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "    (rnn): GRU(4196, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.0955739851165136, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-09 11:51:34,423 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,424 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
      "2020-06-09 11:51:34,425 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,427 Parameters:\n",
      "2020-06-09 11:51:34,429  - learning_rate: \"0.1\"\n",
      "2020-06-09 11:51:34,430  - mini_batch_size: \"64\"\n",
      "2020-06-09 11:51:34,431  - patience: \"3\"\n",
      "2020-06-09 11:51:34,432  - anneal_factor: \"0.5\"\n",
      "2020-06-09 11:51:34,434  - max_epochs: \"10\"\n",
      "2020-06-09 11:51:34,435  - shuffle: \"True\"\n",
      "2020-06-09 11:51:34,436  - train_with_dev: \"False\"\n",
      "2020-06-09 11:51:34,437  - batch_growth_annealing: \"False\"\n",
      "2020-06-09 11:51:34,438 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,439 Model training base path: \"resources/results\"\n",
      "2020-06-09 11:51:34,441 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,442 Device: cpu\n",
      "2020-06-09 11:51:34,443 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:51:34,444 Embeddings storage mode: cpu\n",
      "2020-06-09 11:51:34,446 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-09 11:53:40,607 epoch 1 - iter 6/65 - loss 0.48220217 - samples/sec: 3.04\n",
      "2020-06-09 11:56:19,428 epoch 1 - iter 12/65 - loss 0.32496976 - samples/sec: 2.42\n",
      "2020-06-09 11:57:56,227 epoch 1 - iter 18/65 - loss 0.25963999 - samples/sec: 3.97\n",
      "2020-06-09 11:59:52,669 epoch 1 - iter 24/65 - loss 0.22203907 - samples/sec: 3.30\n",
      "2020-06-09 12:02:18,462 epoch 1 - iter 30/65 - loss 0.20004063 - samples/sec: 2.63\n",
      "2020-06-09 12:04:28,678 epoch 1 - iter 36/65 - loss 0.18591239 - samples/sec: 2.95\n",
      "2020-06-09 12:06:10,520 epoch 1 - iter 42/65 - loss 0.17311122 - samples/sec: 3.77\n",
      "2020-06-09 12:08:21,416 epoch 1 - iter 48/65 - loss 0.16128966 - samples/sec: 2.93\n",
      "2020-06-09 12:10:23,941 epoch 1 - iter 54/65 - loss 0.15419920 - samples/sec: 3.13\n",
      "2020-06-09 12:13:24,220 epoch 1 - iter 60/65 - loss 0.14747600 - samples/sec: 2.13\n"
     ]
    }
   ],
   "source": [
    "#optimising hyperparameters\n",
    "from flair.hyperparameter.param_selection import TextClassifierParamSelector, OptimizationValue\n",
    "from hyperopt import hp\n",
    "from flair.hyperparameter.param_selection import SearchSpace, Parameter\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [[WordEmbeddings('glove'), FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward')]]\n",
    "search_space = SearchSpace()\n",
    "search_space.add(Parameter.EMBEDDINGS, hp.choice, options=word_embeddings)\n",
    "search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128, 256, 512])\n",
    "search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])\n",
    "search_space.add(Parameter.DROPOUT, hp.uniform, low=0.0, high=0.5)\n",
    "search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])\n",
    "search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[16, 32, 64])\n",
    "param_selector = TextClassifierParamSelector(\n",
    "    corpus=corpus, \n",
    "    multi_label=False, \n",
    "    base_path='resources/results', \n",
    "    document_embedding_type='lstm',\n",
    "    max_epochs=10, \n",
    "    training_runs=1,\n",
    "    optimization_value=OptimizationValue.DEV_SCORE\n",
    ")\n",
    "param_selector.optimize(search_space, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
